{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 16:11:31.042730: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-28 16:11:31.113640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 16:11:31.592905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:15:16.008821Z",
     "start_time": "2024-07-28T21:15:14.493201Z"
    }
   },
   "id": "8b9f2ba234180ac1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 418/574 images with exactly one bounding box (72.82%)\n",
      "val set: 73/82 images with exactly one bounding box (89.02%)\n",
      "test set: 55/61 images with exactly one bounding box (90.16%)\n",
      "Ratios (train:val:test): 76.56% : 13.37% : 10.07%\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset directories\n",
    "base_dir = 'fracatlas-DatasetNinja'\n",
    "sets = ['train', 'val', 'test']\n",
    "\n",
    "def filter_images_and_extract_info(set_name):\n",
    "    ann_dir = os.path.join(base_dir, set_name, 'ann')\n",
    "    img_dir = os.path.join(base_dir, set_name, 'img')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for ann_file in os.listdir(ann_dir):\n",
    "        if ann_file.endswith('.json'):\n",
    "            with open(os.path.join(ann_dir, ann_file)) as f:\n",
    "                data_json = json.load(f)\n",
    "                # Count the number of bounding boxes (geometryType: \"rectangle\")\n",
    "                bboxes = [obj for obj in data_json['objects'] if obj['geometryType'] == 'rectangle']\n",
    "                if len(bboxes) == 1:\n",
    "                    bbox = bboxes[0]['points']['exterior']\n",
    "                    xmin, ymin = bbox[0]\n",
    "                    xmax, ymax = bbox[1]\n",
    "                    width = data_json['size']['width']\n",
    "                    height = data_json['size']['height']\n",
    "                    img_file = ann_file.replace('.json', '')\n",
    "                    img_path = os.path.join(img_dir, img_file)\n",
    "                    data.append({\n",
    "                        'filenamepath': img_path,\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'xmin': xmin,\n",
    "                        'ymin': ymin,\n",
    "                        'xmax': xmax,\n",
    "                        'ymax': ymax\n",
    "                    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def count_images(set_name):\n",
    "    ann_dir = os.path.join(base_dir, set_name, 'ann')\n",
    "    return len([f for f in os.listdir(ann_dir) if f.endswith('.json')])\n",
    "\n",
    "def count_and_store_to_dataframe():\n",
    "    all_data = []\n",
    "    total_counts = {}\n",
    "    filtered_counts = {}\n",
    "    \n",
    "    for set_name in sets:\n",
    "        total_images = count_images(set_name)\n",
    "        filtered_data = filter_images_and_extract_info(set_name)\n",
    "        filtered_count = len(filtered_data)\n",
    "        \n",
    "        total_counts[set_name] = total_images\n",
    "        filtered_counts[set_name] = filtered_count\n",
    "        \n",
    "        print(f\"{set_name} set: {filtered_count}/{total_images} images with exactly one bounding box ({(filtered_count / total_images) * 100:.2f}%)\")\n",
    "        \n",
    "        all_data.extend(filtered_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Calculate ratios\n",
    "    total_filtered_images = sum(filtered_counts.values())\n",
    "    train_ratio = (filtered_counts['train'] / total_filtered_images) * 100\n",
    "    val_ratio = (filtered_counts['val'] / total_filtered_images) * 100\n",
    "    test_ratio = (filtered_counts['test'] / total_filtered_images) * 100\n",
    "    \n",
    "    ratios = {\n",
    "        'train_ratio': train_ratio,\n",
    "        'val_ratio': val_ratio,\n",
    "        'test_ratio': test_ratio\n",
    "    }\n",
    "    \n",
    "    print(f\"Ratios (train:val:test): {train_ratio:.2f}% : {val_ratio:.2f}% : {test_ratio:.2f}%\")\n",
    "    \n",
    "    return df, filtered_counts, ratios\n",
    "\n",
    "# Execute the function to count, filter, and store data to a DataFrame\n",
    "df_filtered_images, filtered_counts, ratios = count_and_store_to_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:15:23.323377Z",
     "start_time": "2024-07-28T21:15:18.853802Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        filenamepath  width  height  xmin  \\\n0    fracatlas-DatasetNinja/train/img/IMG0000019.jpg   2304    2880  1242   \n1    fracatlas-DatasetNinja/train/img/IMG0000025.jpg   2880    2304  1466   \n2    fracatlas-DatasetNinja/train/img/IMG0000044.jpg   2304    2880  1426   \n3    fracatlas-DatasetNinja/train/img/IMG0000057.jpg   2304    2880  1130   \n4    fracatlas-DatasetNinja/train/img/IMG0000058.jpg   2304    2880  1190   \n..                                               ...    ...     ...   ...   \n541   fracatlas-DatasetNinja/test/img/IMG0003686.jpg    373     454   180   \n542   fracatlas-DatasetNinja/test/img/IMG0003703.jpg    373     454   154   \n543   fracatlas-DatasetNinja/test/img/IMG0003704.jpg    373     454   177   \n544   fracatlas-DatasetNinja/test/img/IMG0003712.jpg    373     454   157   \n545   fracatlas-DatasetNinja/test/img/IMG0003713.jpg    373     454   157   \n\n     ymin  xmax  ymax  \n0     929  1515  1076  \n1    2010  1621  2163  \n2    1072  1570  1187  \n3    1119  1270  1219  \n4    1349  1285  1511  \n..    ...   ...   ...  \n541   200   216   228  \n542   181   176   218  \n543   138   199   165  \n544   206   168   222  \n545   253   170   266  \n\n[546 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenamepath</th>\n      <th>width</th>\n      <th>height</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fracatlas-DatasetNinja/train/img/IMG0000019.jpg</td>\n      <td>2304</td>\n      <td>2880</td>\n      <td>1242</td>\n      <td>929</td>\n      <td>1515</td>\n      <td>1076</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fracatlas-DatasetNinja/train/img/IMG0000025.jpg</td>\n      <td>2880</td>\n      <td>2304</td>\n      <td>1466</td>\n      <td>2010</td>\n      <td>1621</td>\n      <td>2163</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fracatlas-DatasetNinja/train/img/IMG0000044.jpg</td>\n      <td>2304</td>\n      <td>2880</td>\n      <td>1426</td>\n      <td>1072</td>\n      <td>1570</td>\n      <td>1187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fracatlas-DatasetNinja/train/img/IMG0000057.jpg</td>\n      <td>2304</td>\n      <td>2880</td>\n      <td>1130</td>\n      <td>1119</td>\n      <td>1270</td>\n      <td>1219</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fracatlas-DatasetNinja/train/img/IMG0000058.jpg</td>\n      <td>2304</td>\n      <td>2880</td>\n      <td>1190</td>\n      <td>1349</td>\n      <td>1285</td>\n      <td>1511</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>fracatlas-DatasetNinja/test/img/IMG0003686.jpg</td>\n      <td>373</td>\n      <td>454</td>\n      <td>180</td>\n      <td>200</td>\n      <td>216</td>\n      <td>228</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>fracatlas-DatasetNinja/test/img/IMG0003703.jpg</td>\n      <td>373</td>\n      <td>454</td>\n      <td>154</td>\n      <td>181</td>\n      <td>176</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>fracatlas-DatasetNinja/test/img/IMG0003704.jpg</td>\n      <td>373</td>\n      <td>454</td>\n      <td>177</td>\n      <td>138</td>\n      <td>199</td>\n      <td>165</td>\n    </tr>\n    <tr>\n      <th>544</th>\n      <td>fracatlas-DatasetNinja/test/img/IMG0003712.jpg</td>\n      <td>373</td>\n      <td>454</td>\n      <td>157</td>\n      <td>206</td>\n      <td>168</td>\n      <td>222</td>\n    </tr>\n    <tr>\n      <th>545</th>\n      <td>fracatlas-DatasetNinja/test/img/IMG0003713.jpg</td>\n      <td>373</td>\n      <td>454</td>\n      <td>157</td>\n      <td>253</td>\n      <td>170</td>\n      <td>266</td>\n    </tr>\n  </tbody>\n</table>\n<p>546 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:15:23.386743Z",
     "start_time": "2024-07-28T21:15:23.348297Z"
    }
   },
   "id": "d8af93fc8f640792"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define the target size for the images\n",
    "target_size = (512, 512)  # Desired size for the images\n",
    "\n",
    "# Function to resize image and adjust bounding box\n",
    "def resize_image_and_bbox(image, bbox, original_size, target_size):\n",
    "    orig_w, orig_h = original_size\n",
    "    target_w, target_h = target_size\n",
    "    \n",
    "    # Resize image\n",
    "    resized_image = cv2.resize(image, (target_w, target_h))\n",
    "    \n",
    "    # Scale bounding box\n",
    "    scale_x = target_w / orig_w\n",
    "    scale_y = target_h / orig_h\n",
    "    \n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xmin = int(xmin * scale_x)\n",
    "    ymin = int(ymin * scale_y)\n",
    "    xmax = int(xmax * scale_x)\n",
    "    ymax = int(ymax * scale_y)\n",
    "    \n",
    "    resized_bbox = (xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    return resized_image, resized_bbox\n",
    "\n",
    "# Function to flip image and adjust bounding box horizontally\n",
    "def flip_image_and_bbox(image, bbox):\n",
    "    flipped_image = cv2.flip(image, 1)  # Horizontal flip\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    flipped_bbox = (w - xmax, ymin, w - xmin, ymax)\n",
    "    \n",
    "    return flipped_image, flipped_bbox\n",
    "\n",
    "# Function to process and resize images with augmentation\n",
    "def process_and_resize_images_with_augmentation(df):\n",
    "    all_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        img_path = row['filenamepath']\n",
    "        original_size = (row['width'], row['height'])\n",
    "        bbox = (row['xmin'], row['ymin'], row['xmax'], row['ymax'])\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Image at {img_path} could not be loaded.\")\n",
    "            continue\n",
    "        \n",
    "        # Resize image and bounding box\n",
    "        resized_image, resized_bbox = resize_image_and_bbox(image, bbox, original_size, target_size)\n",
    "        \n",
    "        # Save resized image\n",
    "        save_path = img_path.replace('fracatlas-DatasetNinja', 'fracatlas-DatasetNinja_resized')\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        cv2.imwrite(save_path, resized_image)\n",
    "        \n",
    "        # Store resized bounding box info\n",
    "        resized_data = {\n",
    "            'filenamepath': save_path,\n",
    "            'width': target_size[0],\n",
    "            'height': target_size[1],\n",
    "            'xmin': resized_bbox[0],\n",
    "            'ymin': resized_bbox[1],\n",
    "            'xmax': resized_bbox[2],\n",
    "            'ymax': resized_bbox[3]\n",
    "        }\n",
    "        all_data.append(resized_data)\n",
    "        \n",
    "        # Apply horizontal flip\n",
    "        flipped_image, flipped_bbox = flip_image_and_bbox(resized_image, resized_bbox)\n",
    "        \n",
    "        # Save flipped image\n",
    "        flipped_save_path = save_path.replace('.jpg', '_flipped.jpg')\n",
    "        cv2.imwrite(flipped_save_path, flipped_image)\n",
    "        \n",
    "        # Store flipped bounding box info\n",
    "        flipped_data = {\n",
    "            'filenamepath': flipped_save_path,\n",
    "            'width': target_size[0],\n",
    "            'height': target_size[1],\n",
    "            'xmin': flipped_bbox[0],\n",
    "            'ymin': flipped_bbox[1],\n",
    "            'xmax': flipped_bbox[2],\n",
    "            'ymax': flipped_bbox[3]\n",
    "        }\n",
    "        all_data.append(flipped_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_augmented = pd.DataFrame(all_data)\n",
    "    return df_augmented\n",
    "\n",
    "# Process and resize images with augmentation\n",
    "df_augmented_images = process_and_resize_images_with_augmentation(df_filtered_images)\n",
    "\n",
    "# Extract the split from the filenamepath\n",
    "df_augmented_images['split'] = df_augmented_images['filenamepath'].apply(lambda x: x.split('/')[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:15:40.074191Z",
     "start_time": "2024-07-28T21:15:24.878439Z"
    }
   },
   "id": "5895a6a8f5bf99c5"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           filenamepath  width  height  xmin  \\\n0     fracatlas-DatasetNinja_resized/train/img/IMG00...    512     512   276   \n1     fracatlas-DatasetNinja_resized/train/img/IMG00...    512     512   176   \n2     fracatlas-DatasetNinja_resized/train/img/IMG00...    512     512   260   \n3     fracatlas-DatasetNinja_resized/train/img/IMG00...    512     512   224   \n4     fracatlas-DatasetNinja_resized/train/img/IMG00...    512     512   316   \n...                                                 ...    ...     ...   ...   \n1087  fracatlas-DatasetNinja_resized/test/img/IMG000...    512     512   239   \n1088  fracatlas-DatasetNinja_resized/test/img/IMG000...    512     512   215   \n1089  fracatlas-DatasetNinja_resized/test/img/IMG000...    512     512   282   \n1090  fracatlas-DatasetNinja_resized/test/img/IMG000...    512     512   215   \n1091  fracatlas-DatasetNinja_resized/test/img/IMG000...    512     512   279   \n\n      ymin  xmax  ymax  split  \n0      165   336   191  train  \n1      165   236   191  train  \n2      446   288   480  train  \n3      446   252   480  train  \n4      190   348   211  train  \n...    ...   ...   ...    ...  \n1087   155   270   186   test  \n1088   232   230   250   test  \n1089   232   297   250   test  \n1090   285   233   299   test  \n1091   285   297   299   test  \n\n[1092 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenamepath</th>\n      <th>width</th>\n      <th>height</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fracatlas-DatasetNinja_resized/train/img/IMG00...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>276</td>\n      <td>165</td>\n      <td>336</td>\n      <td>191</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fracatlas-DatasetNinja_resized/train/img/IMG00...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>176</td>\n      <td>165</td>\n      <td>236</td>\n      <td>191</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fracatlas-DatasetNinja_resized/train/img/IMG00...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>260</td>\n      <td>446</td>\n      <td>288</td>\n      <td>480</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fracatlas-DatasetNinja_resized/train/img/IMG00...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>224</td>\n      <td>446</td>\n      <td>252</td>\n      <td>480</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fracatlas-DatasetNinja_resized/train/img/IMG00...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>316</td>\n      <td>190</td>\n      <td>348</td>\n      <td>211</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1087</th>\n      <td>fracatlas-DatasetNinja_resized/test/img/IMG000...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>239</td>\n      <td>155</td>\n      <td>270</td>\n      <td>186</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1088</th>\n      <td>fracatlas-DatasetNinja_resized/test/img/IMG000...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>215</td>\n      <td>232</td>\n      <td>230</td>\n      <td>250</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1089</th>\n      <td>fracatlas-DatasetNinja_resized/test/img/IMG000...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>282</td>\n      <td>232</td>\n      <td>297</td>\n      <td>250</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1090</th>\n      <td>fracatlas-DatasetNinja_resized/test/img/IMG000...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>215</td>\n      <td>285</td>\n      <td>233</td>\n      <td>299</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1091</th>\n      <td>fracatlas-DatasetNinja_resized/test/img/IMG000...</td>\n      <td>512</td>\n      <td>512</td>\n      <td>279</td>\n      <td>285</td>\n      <td>297</td>\n      <td>299</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>1092 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented_images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T21:57:23.954427Z",
     "start_time": "2024-07-27T21:57:23.884204Z"
    }
   },
   "id": "ae5207e3a25c0db9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define the custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transforms=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = row['filenamepath']\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = [[row['xmin'], row['ymin'], row['xmax'], row['ymax']]]\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        labels = torch.ones((len(boxes),), dtype=torch.int64)  # All objects belong to the same class (1)\n",
    "        image_id = torch.tensor([idx])\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": image_id\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(torchvision.transforms.RandomHorizontalFlip(0.5))\n",
    "    return torchvision.transforms.Compose(transforms)\n",
    "\n",
    "# Split the dataframe into train, val, and test\n",
    "train_df = df_augmented_images[df_augmented_images['split'] == 'train']\n",
    "val_df = df_augmented_images[df_augmented_images['split'] == 'val']\n",
    "test_df = df_augmented_images[df_augmented_images['split'] == 'test']\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_df, get_transform(train=True))\n",
    "val_dataset = CustomDataset(val_df, get_transform(train=False))\n",
    "test_dataset = CustomDataset(test_df, get_transform(train=False))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=8, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8, collate_fn=lambda x: tuple(zip(*x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:15:58.307311Z",
     "start_time": "2024-07-28T21:15:57.304463Z"
    }
   },
   "id": "c78f92e7429c8f40"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    # Load a model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:27:14.615792Z",
     "start_time": "2024-07-28T21:27:13.313555Z"
    }
   },
   "id": "8d33e6ebf8298778"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yzysnake/miniconda3/envs/rapids-24.02/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_classes = 2  # 1 class (object) + 1 class (background)\n",
    "model = get_model(num_classes)\n",
    "\n",
    "# Move model to the right device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Custom function to compute the validation loss\n",
    "def compute_loss(model, images, targets):\n",
    "    model.train()\n",
    "    loss_dict = model(images, targets)\n",
    "    losses = sum(loss for loss in loss_dict.values())\n",
    "    return losses\n",
    "\n",
    "# Training and evaluation code\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:27:21.425451Z",
     "start_time": "2024-07-28T21:27:20.781509Z"
    }
   },
   "id": "4a8ded8b6fd017b4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] [Batch 0/836] [Loss: 0.9758]\n",
      "[Epoch 1/10] [Batch 10/836] [Loss: 0.1248]\n",
      "[Epoch 1/10] [Batch 20/836] [Loss: 0.2475]\n",
      "[Epoch 1/10] [Batch 30/836] [Loss: 0.2546]\n",
      "[Epoch 1/10] [Batch 40/836] [Loss: 0.1560]\n",
      "[Epoch 1/10] [Batch 50/836] [Loss: 0.2569]\n",
      "[Epoch 1/10] [Batch 60/836] [Loss: 0.1833]\n",
      "[Epoch 1/10] [Batch 70/836] [Loss: 0.2197]\n",
      "[Epoch 1/10] [Batch 80/836] [Loss: 0.1864]\n",
      "[Epoch 1/10] [Batch 90/836] [Loss: 0.1322]\n",
      "[Epoch 1/10] [Batch 100/836] [Loss: 0.1038]\n",
      "[Epoch 1/10] [Batch 110/836] [Loss: 0.2101]\n",
      "[Epoch 1/10] [Batch 120/836] [Loss: 0.2377]\n",
      "[Epoch 1/10] [Batch 130/836] [Loss: 0.2889]\n",
      "[Epoch 1/10] [Batch 140/836] [Loss: 0.0833]\n",
      "[Epoch 1/10] [Batch 150/836] [Loss: 0.0732]\n",
      "[Epoch 1/10] [Batch 160/836] [Loss: 0.1739]\n",
      "[Epoch 1/10] [Batch 170/836] [Loss: 0.3012]\n",
      "[Epoch 1/10] [Batch 180/836] [Loss: 0.1426]\n",
      "[Epoch 1/10] [Batch 190/836] [Loss: 0.1667]\n",
      "[Epoch 1/10] [Batch 200/836] [Loss: 0.2538]\n",
      "[Epoch 1/10] [Batch 210/836] [Loss: 0.1603]\n",
      "[Epoch 1/10] [Batch 220/836] [Loss: 0.2549]\n",
      "[Epoch 1/10] [Batch 230/836] [Loss: 0.2087]\n",
      "[Epoch 1/10] [Batch 240/836] [Loss: 0.1035]\n",
      "[Epoch 1/10] [Batch 250/836] [Loss: 0.1540]\n",
      "[Epoch 1/10] [Batch 260/836] [Loss: 0.0722]\n",
      "[Epoch 1/10] [Batch 270/836] [Loss: 0.1572]\n",
      "[Epoch 1/10] [Batch 280/836] [Loss: 0.3223]\n",
      "[Epoch 1/10] [Batch 290/836] [Loss: 0.1209]\n",
      "[Epoch 1/10] [Batch 300/836] [Loss: 0.1894]\n",
      "[Epoch 1/10] [Batch 310/836] [Loss: 0.1107]\n",
      "[Epoch 1/10] [Batch 320/836] [Loss: 0.1140]\n",
      "[Epoch 1/10] [Batch 330/836] [Loss: 0.2447]\n",
      "[Epoch 1/10] [Batch 340/836] [Loss: 0.2027]\n",
      "[Epoch 1/10] [Batch 350/836] [Loss: 0.1303]\n",
      "[Epoch 1/10] [Batch 360/836] [Loss: 0.2049]\n",
      "[Epoch 1/10] [Batch 370/836] [Loss: 0.0889]\n",
      "[Epoch 1/10] [Batch 380/836] [Loss: 0.1793]\n",
      "[Epoch 1/10] [Batch 390/836] [Loss: 0.0782]\n",
      "[Epoch 1/10] [Batch 400/836] [Loss: 0.1011]\n",
      "[Epoch 1/10] [Batch 410/836] [Loss: 0.2214]\n",
      "[Epoch 1/10] [Batch 420/836] [Loss: 0.1843]\n",
      "[Epoch 1/10] [Batch 430/836] [Loss: 0.1101]\n",
      "[Epoch 1/10] [Batch 440/836] [Loss: 0.2103]\n",
      "[Epoch 1/10] [Batch 450/836] [Loss: 0.1179]\n",
      "[Epoch 1/10] [Batch 460/836] [Loss: 0.2130]\n",
      "[Epoch 1/10] [Batch 470/836] [Loss: 0.2163]\n",
      "[Epoch 1/10] [Batch 480/836] [Loss: 0.2051]\n",
      "[Epoch 1/10] [Batch 490/836] [Loss: 0.1210]\n",
      "[Epoch 1/10] [Batch 500/836] [Loss: 0.1118]\n",
      "[Epoch 1/10] [Batch 510/836] [Loss: 0.2184]\n",
      "[Epoch 1/10] [Batch 520/836] [Loss: 0.0984]\n",
      "[Epoch 1/10] [Batch 530/836] [Loss: 0.2107]\n",
      "[Epoch 1/10] [Batch 540/836] [Loss: 0.3834]\n",
      "[Epoch 1/10] [Batch 550/836] [Loss: 0.2995]\n",
      "[Epoch 1/10] [Batch 560/836] [Loss: 0.3618]\n",
      "[Epoch 1/10] [Batch 570/836] [Loss: 0.3504]\n",
      "[Epoch 1/10] [Batch 580/836] [Loss: 0.2325]\n",
      "[Epoch 1/10] [Batch 590/836] [Loss: 0.1432]\n",
      "[Epoch 1/10] [Batch 600/836] [Loss: 0.0836]\n",
      "[Epoch 1/10] [Batch 610/836] [Loss: 0.1394]\n",
      "[Epoch 1/10] [Batch 620/836] [Loss: 0.2713]\n",
      "[Epoch 1/10] [Batch 630/836] [Loss: 0.1029]\n",
      "[Epoch 1/10] [Batch 640/836] [Loss: 0.1776]\n",
      "[Epoch 1/10] [Batch 650/836] [Loss: 0.1779]\n",
      "[Epoch 1/10] [Batch 660/836] [Loss: 0.1032]\n",
      "[Epoch 1/10] [Batch 670/836] [Loss: 0.1215]\n",
      "[Epoch 1/10] [Batch 680/836] [Loss: 0.1779]\n",
      "[Epoch 1/10] [Batch 690/836] [Loss: 0.1070]\n",
      "[Epoch 1/10] [Batch 700/836] [Loss: 0.2200]\n",
      "[Epoch 1/10] [Batch 710/836] [Loss: 0.0811]\n",
      "[Epoch 1/10] [Batch 720/836] [Loss: 0.1525]\n",
      "[Epoch 1/10] [Batch 730/836] [Loss: 0.0825]\n",
      "[Epoch 1/10] [Batch 740/836] [Loss: 0.0742]\n",
      "[Epoch 1/10] [Batch 750/836] [Loss: 0.1900]\n",
      "[Epoch 1/10] [Batch 760/836] [Loss: 0.1259]\n",
      "[Epoch 1/10] [Batch 770/836] [Loss: 0.1803]\n",
      "[Epoch 1/10] [Batch 780/836] [Loss: 0.0876]\n",
      "[Epoch 1/10] [Batch 790/836] [Loss: 0.1184]\n",
      "[Epoch 1/10] [Batch 800/836] [Loss: 0.1366]\n",
      "[Epoch 1/10] [Batch 810/836] [Loss: 0.1361]\n",
      "[Epoch 1/10] [Batch 820/836] [Loss: 0.1629]\n",
      "[Epoch 1/10] [Batch 830/836] [Loss: 0.1470]\n",
      "[Epoch 1/10] [Training Loss: 0.1755] [Time: 46.08s]\n",
      "[Epoch 1/10] [Validation Loss: 0.1890]\n",
      "[Epoch 2/10] [Batch 0/836] [Loss: 0.2400]\n",
      "[Epoch 2/10] [Batch 10/836] [Loss: 0.3205]\n",
      "[Epoch 2/10] [Batch 20/836] [Loss: 0.2947]\n",
      "[Epoch 2/10] [Batch 30/836] [Loss: 0.1770]\n",
      "[Epoch 2/10] [Batch 40/836] [Loss: 0.1111]\n",
      "[Epoch 2/10] [Batch 50/836] [Loss: 0.1245]\n",
      "[Epoch 2/10] [Batch 60/836] [Loss: 0.0900]\n",
      "[Epoch 2/10] [Batch 70/836] [Loss: 0.2429]\n",
      "[Epoch 2/10] [Batch 80/836] [Loss: 0.2271]\n",
      "[Epoch 2/10] [Batch 90/836] [Loss: 0.2412]\n",
      "[Epoch 2/10] [Batch 100/836] [Loss: 0.2607]\n",
      "[Epoch 2/10] [Batch 110/836] [Loss: 0.1784]\n",
      "[Epoch 2/10] [Batch 120/836] [Loss: 0.1619]\n",
      "[Epoch 2/10] [Batch 130/836] [Loss: 0.2665]\n",
      "[Epoch 2/10] [Batch 140/836] [Loss: 0.1687]\n",
      "[Epoch 2/10] [Batch 150/836] [Loss: 0.1035]\n",
      "[Epoch 2/10] [Batch 160/836] [Loss: 0.1700]\n",
      "[Epoch 2/10] [Batch 170/836] [Loss: 0.2372]\n",
      "[Epoch 2/10] [Batch 180/836] [Loss: 0.1104]\n",
      "[Epoch 2/10] [Batch 190/836] [Loss: 0.1933]\n",
      "[Epoch 2/10] [Batch 200/836] [Loss: 0.1976]\n",
      "[Epoch 2/10] [Batch 210/836] [Loss: 0.2886]\n",
      "[Epoch 2/10] [Batch 220/836] [Loss: 0.1276]\n",
      "[Epoch 2/10] [Batch 230/836] [Loss: 0.1017]\n",
      "[Epoch 2/10] [Batch 240/836] [Loss: 0.1164]\n",
      "[Epoch 2/10] [Batch 250/836] [Loss: 0.1387]\n",
      "[Epoch 2/10] [Batch 260/836] [Loss: 0.2459]\n",
      "[Epoch 2/10] [Batch 270/836] [Loss: 0.1856]\n",
      "[Epoch 2/10] [Batch 280/836] [Loss: 0.2458]\n",
      "[Epoch 2/10] [Batch 290/836] [Loss: 0.2972]\n",
      "[Epoch 2/10] [Batch 300/836] [Loss: 0.1046]\n",
      "[Epoch 2/10] [Batch 310/836] [Loss: 0.1843]\n",
      "[Epoch 2/10] [Batch 320/836] [Loss: 0.2628]\n",
      "[Epoch 2/10] [Batch 330/836] [Loss: 0.2185]\n",
      "[Epoch 2/10] [Batch 340/836] [Loss: 0.2121]\n",
      "[Epoch 2/10] [Batch 350/836] [Loss: 0.1055]\n",
      "[Epoch 2/10] [Batch 360/836] [Loss: 0.4128]\n",
      "[Epoch 2/10] [Batch 370/836] [Loss: 0.1815]\n",
      "[Epoch 2/10] [Batch 380/836] [Loss: 0.1268]\n",
      "[Epoch 2/10] [Batch 390/836] [Loss: 0.1155]\n",
      "[Epoch 2/10] [Batch 400/836] [Loss: 0.1618]\n",
      "[Epoch 2/10] [Batch 410/836] [Loss: 0.1670]\n",
      "[Epoch 2/10] [Batch 420/836] [Loss: 0.3312]\n",
      "[Epoch 2/10] [Batch 430/836] [Loss: 0.2249]\n",
      "[Epoch 2/10] [Batch 440/836] [Loss: 0.1450]\n",
      "[Epoch 2/10] [Batch 450/836] [Loss: 0.1040]\n",
      "[Epoch 2/10] [Batch 460/836] [Loss: 0.3466]\n",
      "[Epoch 2/10] [Batch 470/836] [Loss: 0.2416]\n",
      "[Epoch 2/10] [Batch 480/836] [Loss: 0.1749]\n",
      "[Epoch 2/10] [Batch 490/836] [Loss: 0.1909]\n",
      "[Epoch 2/10] [Batch 500/836] [Loss: 0.1449]\n",
      "[Epoch 2/10] [Batch 510/836] [Loss: 0.1172]\n",
      "[Epoch 2/10] [Batch 520/836] [Loss: 0.2164]\n",
      "[Epoch 2/10] [Batch 530/836] [Loss: 0.2480]\n",
      "[Epoch 2/10] [Batch 540/836] [Loss: 0.2134]\n",
      "[Epoch 2/10] [Batch 550/836] [Loss: 0.2004]\n",
      "[Epoch 2/10] [Batch 560/836] [Loss: 0.2406]\n",
      "[Epoch 2/10] [Batch 570/836] [Loss: 0.1221]\n",
      "[Epoch 2/10] [Batch 580/836] [Loss: 0.2044]\n",
      "[Epoch 2/10] [Batch 590/836] [Loss: 0.1315]\n",
      "[Epoch 2/10] [Batch 600/836] [Loss: 0.1001]\n",
      "[Epoch 2/10] [Batch 610/836] [Loss: 0.2086]\n",
      "[Epoch 2/10] [Batch 620/836] [Loss: 0.1877]\n",
      "[Epoch 2/10] [Batch 630/836] [Loss: 0.2025]\n",
      "[Epoch 2/10] [Batch 640/836] [Loss: 0.1610]\n",
      "[Epoch 2/10] [Batch 650/836] [Loss: 0.1143]\n",
      "[Epoch 2/10] [Batch 660/836] [Loss: 0.1519]\n",
      "[Epoch 2/10] [Batch 670/836] [Loss: 0.1460]\n",
      "[Epoch 2/10] [Batch 680/836] [Loss: 0.2985]\n",
      "[Epoch 2/10] [Batch 690/836] [Loss: 0.1231]\n",
      "[Epoch 2/10] [Batch 700/836] [Loss: 0.0802]\n",
      "[Epoch 2/10] [Batch 710/836] [Loss: 0.1259]\n",
      "[Epoch 2/10] [Batch 720/836] [Loss: 0.0633]\n",
      "[Epoch 2/10] [Batch 730/836] [Loss: 0.1898]\n",
      "[Epoch 2/10] [Batch 740/836] [Loss: 0.1520]\n",
      "[Epoch 2/10] [Batch 750/836] [Loss: 0.1001]\n",
      "[Epoch 2/10] [Batch 760/836] [Loss: 0.1884]\n",
      "[Epoch 2/10] [Batch 770/836] [Loss: 0.1917]\n",
      "[Epoch 2/10] [Batch 780/836] [Loss: 0.0965]\n",
      "[Epoch 2/10] [Batch 790/836] [Loss: 0.1694]\n",
      "[Epoch 2/10] [Batch 800/836] [Loss: 0.1564]\n",
      "[Epoch 2/10] [Batch 810/836] [Loss: 0.1793]\n",
      "[Epoch 2/10] [Batch 820/836] [Loss: 0.2866]\n",
      "[Epoch 2/10] [Batch 830/836] [Loss: 0.2293]\n",
      "[Epoch 2/10] [Training Loss: 0.1801] [Time: 45.31s]\n",
      "[Epoch 2/10] [Validation Loss: 0.1898]\n",
      "[Epoch 3/10] [Batch 0/836] [Loss: 0.1678]\n",
      "[Epoch 3/10] [Batch 10/836] [Loss: 0.0656]\n",
      "[Epoch 3/10] [Batch 20/836] [Loss: 0.1259]\n",
      "[Epoch 3/10] [Batch 30/836] [Loss: 0.0878]\n",
      "[Epoch 3/10] [Batch 40/836] [Loss: 0.1215]\n",
      "[Epoch 3/10] [Batch 50/836] [Loss: 0.0675]\n",
      "[Epoch 3/10] [Batch 60/836] [Loss: 0.0759]\n",
      "[Epoch 3/10] [Batch 70/836] [Loss: 0.1789]\n",
      "[Epoch 3/10] [Batch 80/836] [Loss: 0.1045]\n",
      "[Epoch 3/10] [Batch 90/836] [Loss: 0.0654]\n",
      "[Epoch 3/10] [Batch 100/836] [Loss: 0.1582]\n",
      "[Epoch 3/10] [Batch 110/836] [Loss: 0.1978]\n",
      "[Epoch 3/10] [Batch 120/836] [Loss: 0.1676]\n",
      "[Epoch 3/10] [Batch 130/836] [Loss: 0.1208]\n",
      "[Epoch 3/10] [Batch 140/836] [Loss: 0.1465]\n",
      "[Epoch 3/10] [Batch 150/836] [Loss: 0.1032]\n",
      "[Epoch 3/10] [Batch 160/836] [Loss: 0.0981]\n",
      "[Epoch 3/10] [Batch 170/836] [Loss: 0.2112]\n",
      "[Epoch 3/10] [Batch 180/836] [Loss: 0.0477]\n",
      "[Epoch 3/10] [Batch 190/836] [Loss: 0.2628]\n",
      "[Epoch 3/10] [Batch 200/836] [Loss: 0.1007]\n",
      "[Epoch 3/10] [Batch 210/836] [Loss: 0.0825]\n",
      "[Epoch 3/10] [Batch 220/836] [Loss: 0.1280]\n",
      "[Epoch 3/10] [Batch 230/836] [Loss: 0.2230]\n",
      "[Epoch 3/10] [Batch 240/836] [Loss: 0.2840]\n",
      "[Epoch 3/10] [Batch 250/836] [Loss: 0.1350]\n",
      "[Epoch 3/10] [Batch 260/836] [Loss: 0.2081]\n",
      "[Epoch 3/10] [Batch 270/836] [Loss: 0.1391]\n",
      "[Epoch 3/10] [Batch 280/836] [Loss: 0.1333]\n",
      "[Epoch 3/10] [Batch 290/836] [Loss: 0.1290]\n",
      "[Epoch 3/10] [Batch 300/836] [Loss: 0.2312]\n",
      "[Epoch 3/10] [Batch 310/836] [Loss: 0.0812]\n",
      "[Epoch 3/10] [Batch 320/836] [Loss: 0.2283]\n",
      "[Epoch 3/10] [Batch 330/836] [Loss: 0.0914]\n",
      "[Epoch 3/10] [Batch 340/836] [Loss: 0.1457]\n",
      "[Epoch 3/10] [Batch 350/836] [Loss: 0.0999]\n",
      "[Epoch 3/10] [Batch 360/836] [Loss: 0.2182]\n",
      "[Epoch 3/10] [Batch 370/836] [Loss: 0.0994]\n",
      "[Epoch 3/10] [Batch 380/836] [Loss: 0.2388]\n",
      "[Epoch 3/10] [Batch 390/836] [Loss: 0.1133]\n",
      "[Epoch 3/10] [Batch 400/836] [Loss: 0.1873]\n",
      "[Epoch 3/10] [Batch 410/836] [Loss: 0.2723]\n",
      "[Epoch 3/10] [Batch 420/836] [Loss: 0.1868]\n",
      "[Epoch 3/10] [Batch 430/836] [Loss: 0.1126]\n",
      "[Epoch 3/10] [Batch 440/836] [Loss: 0.0945]\n",
      "[Epoch 3/10] [Batch 450/836] [Loss: 0.1506]\n",
      "[Epoch 3/10] [Batch 460/836] [Loss: 0.1031]\n",
      "[Epoch 3/10] [Batch 470/836] [Loss: 0.1414]\n",
      "[Epoch 3/10] [Batch 480/836] [Loss: 0.1748]\n",
      "[Epoch 3/10] [Batch 490/836] [Loss: 0.2195]\n",
      "[Epoch 3/10] [Batch 500/836] [Loss: 0.1371]\n",
      "[Epoch 3/10] [Batch 510/836] [Loss: 0.1504]\n",
      "[Epoch 3/10] [Batch 520/836] [Loss: 0.0923]\n",
      "[Epoch 3/10] [Batch 530/836] [Loss: 0.1236]\n",
      "[Epoch 3/10] [Batch 540/836] [Loss: 0.1652]\n",
      "[Epoch 3/10] [Batch 550/836] [Loss: 0.3623]\n",
      "[Epoch 3/10] [Batch 560/836] [Loss: 0.1125]\n",
      "[Epoch 3/10] [Batch 570/836] [Loss: 0.1642]\n",
      "[Epoch 3/10] [Batch 580/836] [Loss: 0.1923]\n",
      "[Epoch 3/10] [Batch 590/836] [Loss: 0.1802]\n",
      "[Epoch 3/10] [Batch 600/836] [Loss: 0.0865]\n",
      "[Epoch 3/10] [Batch 610/836] [Loss: 0.1793]\n",
      "[Epoch 3/10] [Batch 620/836] [Loss: 0.2554]\n",
      "[Epoch 3/10] [Batch 630/836] [Loss: 0.1320]\n",
      "[Epoch 3/10] [Batch 640/836] [Loss: 0.0868]\n",
      "[Epoch 3/10] [Batch 650/836] [Loss: 0.0897]\n",
      "[Epoch 3/10] [Batch 660/836] [Loss: 0.2583]\n",
      "[Epoch 3/10] [Batch 670/836] [Loss: 0.1141]\n",
      "[Epoch 3/10] [Batch 680/836] [Loss: 0.1627]\n",
      "[Epoch 3/10] [Batch 690/836] [Loss: 0.1902]\n",
      "[Epoch 3/10] [Batch 700/836] [Loss: 0.0900]\n",
      "[Epoch 3/10] [Batch 710/836] [Loss: 0.1618]\n",
      "[Epoch 3/10] [Batch 720/836] [Loss: 0.1243]\n",
      "[Epoch 3/10] [Batch 730/836] [Loss: 0.1474]\n",
      "[Epoch 3/10] [Batch 740/836] [Loss: 0.1305]\n",
      "[Epoch 3/10] [Batch 750/836] [Loss: 0.1304]\n",
      "[Epoch 3/10] [Batch 760/836] [Loss: 0.1970]\n",
      "[Epoch 3/10] [Batch 770/836] [Loss: 0.1376]\n",
      "[Epoch 3/10] [Batch 780/836] [Loss: 0.0966]\n",
      "[Epoch 3/10] [Batch 790/836] [Loss: 0.1916]\n",
      "[Epoch 3/10] [Batch 800/836] [Loss: 0.1612]\n",
      "[Epoch 3/10] [Batch 810/836] [Loss: 0.1330]\n",
      "[Epoch 3/10] [Batch 820/836] [Loss: 0.1051]\n",
      "[Epoch 3/10] [Batch 830/836] [Loss: 0.2260]\n",
      "[Epoch 3/10] [Training Loss: 0.1747] [Time: 47.25s]\n",
      "[Epoch 3/10] [Validation Loss: 0.1725]\n",
      "[Epoch 4/10] [Batch 0/836] [Loss: 0.1296]\n",
      "[Epoch 4/10] [Batch 10/836] [Loss: 0.2456]\n",
      "[Epoch 4/10] [Batch 20/836] [Loss: 0.1834]\n",
      "[Epoch 4/10] [Batch 30/836] [Loss: 0.2304]\n",
      "[Epoch 4/10] [Batch 40/836] [Loss: 0.3428]\n",
      "[Epoch 4/10] [Batch 50/836] [Loss: 0.1413]\n",
      "[Epoch 4/10] [Batch 60/836] [Loss: 0.1867]\n",
      "[Epoch 4/10] [Batch 70/836] [Loss: 0.0758]\n",
      "[Epoch 4/10] [Batch 80/836] [Loss: 0.1225]\n",
      "[Epoch 4/10] [Batch 90/836] [Loss: 0.2119]\n",
      "[Epoch 4/10] [Batch 100/836] [Loss: 0.0994]\n",
      "[Epoch 4/10] [Batch 110/836] [Loss: 0.2295]\n",
      "[Epoch 4/10] [Batch 120/836] [Loss: 0.2296]\n",
      "[Epoch 4/10] [Batch 130/836] [Loss: 0.1829]\n",
      "[Epoch 4/10] [Batch 140/836] [Loss: 0.2194]\n",
      "[Epoch 4/10] [Batch 150/836] [Loss: 0.0688]\n",
      "[Epoch 4/10] [Batch 160/836] [Loss: 0.1558]\n",
      "[Epoch 4/10] [Batch 170/836] [Loss: 0.0857]\n",
      "[Epoch 4/10] [Batch 180/836] [Loss: 0.1244]\n",
      "[Epoch 4/10] [Batch 190/836] [Loss: 0.0555]\n",
      "[Epoch 4/10] [Batch 200/836] [Loss: 0.2051]\n",
      "[Epoch 4/10] [Batch 210/836] [Loss: 0.1756]\n",
      "[Epoch 4/10] [Batch 220/836] [Loss: 0.1026]\n",
      "[Epoch 4/10] [Batch 230/836] [Loss: 0.1687]\n",
      "[Epoch 4/10] [Batch 240/836] [Loss: 0.1310]\n",
      "[Epoch 4/10] [Batch 250/836] [Loss: 0.1427]\n",
      "[Epoch 4/10] [Batch 260/836] [Loss: 0.2378]\n",
      "[Epoch 4/10] [Batch 270/836] [Loss: 0.0900]\n",
      "[Epoch 4/10] [Batch 280/836] [Loss: 0.1623]\n",
      "[Epoch 4/10] [Batch 290/836] [Loss: 0.1155]\n",
      "[Epoch 4/10] [Batch 300/836] [Loss: 0.0980]\n",
      "[Epoch 4/10] [Batch 310/836] [Loss: 0.2324]\n",
      "[Epoch 4/10] [Batch 320/836] [Loss: 0.3161]\n",
      "[Epoch 4/10] [Batch 330/836] [Loss: 0.1269]\n",
      "[Epoch 4/10] [Batch 340/836] [Loss: 0.2122]\n",
      "[Epoch 4/10] [Batch 350/836] [Loss: 0.1064]\n",
      "[Epoch 4/10] [Batch 360/836] [Loss: 0.0773]\n",
      "[Epoch 4/10] [Batch 370/836] [Loss: 0.0706]\n",
      "[Epoch 4/10] [Batch 380/836] [Loss: 0.2998]\n",
      "[Epoch 4/10] [Batch 390/836] [Loss: 0.1025]\n",
      "[Epoch 4/10] [Batch 400/836] [Loss: 0.1824]\n",
      "[Epoch 4/10] [Batch 410/836] [Loss: 0.2726]\n",
      "[Epoch 4/10] [Batch 420/836] [Loss: 0.1371]\n",
      "[Epoch 4/10] [Batch 430/836] [Loss: 0.0967]\n",
      "[Epoch 4/10] [Batch 440/836] [Loss: 0.1398]\n",
      "[Epoch 4/10] [Batch 450/836] [Loss: 0.0567]\n",
      "[Epoch 4/10] [Batch 460/836] [Loss: 0.0732]\n",
      "[Epoch 4/10] [Batch 470/836] [Loss: 0.0665]\n",
      "[Epoch 4/10] [Batch 480/836] [Loss: 0.0978]\n",
      "[Epoch 4/10] [Batch 490/836] [Loss: 0.1767]\n",
      "[Epoch 4/10] [Batch 500/836] [Loss: 0.1544]\n",
      "[Epoch 4/10] [Batch 510/836] [Loss: 0.2250]\n",
      "[Epoch 4/10] [Batch 520/836] [Loss: 0.1541]\n",
      "[Epoch 4/10] [Batch 530/836] [Loss: 0.1757]\n",
      "[Epoch 4/10] [Batch 540/836] [Loss: 0.1642]\n",
      "[Epoch 4/10] [Batch 550/836] [Loss: 0.1573]\n",
      "[Epoch 4/10] [Batch 560/836] [Loss: 0.1637]\n",
      "[Epoch 4/10] [Batch 570/836] [Loss: 0.1913]\n",
      "[Epoch 4/10] [Batch 580/836] [Loss: 0.1020]\n",
      "[Epoch 4/10] [Batch 590/836] [Loss: 0.1216]\n",
      "[Epoch 4/10] [Batch 600/836] [Loss: 0.2924]\n",
      "[Epoch 4/10] [Batch 610/836] [Loss: 0.1088]\n",
      "[Epoch 4/10] [Batch 620/836] [Loss: 0.0992]\n",
      "[Epoch 4/10] [Batch 630/836] [Loss: 0.1377]\n",
      "[Epoch 4/10] [Batch 640/836] [Loss: 0.1325]\n",
      "[Epoch 4/10] [Batch 650/836] [Loss: 0.0997]\n",
      "[Epoch 4/10] [Batch 660/836] [Loss: 0.1452]\n",
      "[Epoch 4/10] [Batch 670/836] [Loss: 0.0798]\n",
      "[Epoch 4/10] [Batch 680/836] [Loss: 0.1095]\n",
      "[Epoch 4/10] [Batch 690/836] [Loss: 0.1318]\n",
      "[Epoch 4/10] [Batch 700/836] [Loss: 0.1859]\n",
      "[Epoch 4/10] [Batch 710/836] [Loss: 0.1122]\n",
      "[Epoch 4/10] [Batch 720/836] [Loss: 0.1051]\n",
      "[Epoch 4/10] [Batch 730/836] [Loss: 0.3664]\n",
      "[Epoch 4/10] [Batch 740/836] [Loss: 0.1289]\n",
      "[Epoch 4/10] [Batch 750/836] [Loss: 0.3277]\n",
      "[Epoch 4/10] [Batch 760/836] [Loss: 0.1687]\n",
      "[Epoch 4/10] [Batch 770/836] [Loss: 0.1692]\n",
      "[Epoch 4/10] [Batch 780/836] [Loss: 0.2574]\n",
      "[Epoch 4/10] [Batch 790/836] [Loss: 0.2411]\n",
      "[Epoch 4/10] [Batch 800/836] [Loss: 0.2712]\n",
      "[Epoch 4/10] [Batch 810/836] [Loss: 0.1199]\n",
      "[Epoch 4/10] [Batch 820/836] [Loss: 0.1556]\n",
      "[Epoch 4/10] [Batch 830/836] [Loss: 0.1762]\n",
      "[Epoch 4/10] [Training Loss: 0.1648] [Time: 46.23s]\n",
      "[Epoch 4/10] [Validation Loss: 0.1778]\n",
      "[Epoch 5/10] [Batch 0/836] [Loss: 0.1127]\n",
      "[Epoch 5/10] [Batch 10/836] [Loss: 0.1033]\n",
      "[Epoch 5/10] [Batch 20/836] [Loss: 0.1205]\n",
      "[Epoch 5/10] [Batch 30/836] [Loss: 0.1348]\n",
      "[Epoch 5/10] [Batch 40/836] [Loss: 0.2825]\n",
      "[Epoch 5/10] [Batch 50/836] [Loss: 0.2283]\n",
      "[Epoch 5/10] [Batch 60/836] [Loss: 0.0977]\n",
      "[Epoch 5/10] [Batch 70/836] [Loss: 0.1115]\n",
      "[Epoch 5/10] [Batch 80/836] [Loss: 0.1027]\n",
      "[Epoch 5/10] [Batch 90/836] [Loss: 0.0938]\n",
      "[Epoch 5/10] [Batch 100/836] [Loss: 0.0982]\n",
      "[Epoch 5/10] [Batch 110/836] [Loss: 0.0904]\n",
      "[Epoch 5/10] [Batch 120/836] [Loss: 0.0806]\n",
      "[Epoch 5/10] [Batch 130/836] [Loss: 0.2307]\n",
      "[Epoch 5/10] [Batch 140/836] [Loss: 0.2865]\n",
      "[Epoch 5/10] [Batch 150/836] [Loss: 0.0935]\n",
      "[Epoch 5/10] [Batch 160/836] [Loss: 0.2540]\n",
      "[Epoch 5/10] [Batch 170/836] [Loss: 0.1503]\n",
      "[Epoch 5/10] [Batch 180/836] [Loss: 0.1015]\n",
      "[Epoch 5/10] [Batch 190/836] [Loss: 0.1367]\n",
      "[Epoch 5/10] [Batch 200/836] [Loss: 0.1194]\n",
      "[Epoch 5/10] [Batch 210/836] [Loss: 0.1096]\n",
      "[Epoch 5/10] [Batch 220/836] [Loss: 0.1144]\n",
      "[Epoch 5/10] [Batch 230/836] [Loss: 0.0832]\n",
      "[Epoch 5/10] [Batch 240/836] [Loss: 0.3285]\n",
      "[Epoch 5/10] [Batch 250/836] [Loss: 0.1007]\n",
      "[Epoch 5/10] [Batch 260/836] [Loss: 0.2312]\n",
      "[Epoch 5/10] [Batch 270/836] [Loss: 0.2393]\n",
      "[Epoch 5/10] [Batch 280/836] [Loss: 0.1580]\n",
      "[Epoch 5/10] [Batch 290/836] [Loss: 0.1536]\n",
      "[Epoch 5/10] [Batch 300/836] [Loss: 0.2683]\n",
      "[Epoch 5/10] [Batch 310/836] [Loss: 0.1244]\n",
      "[Epoch 5/10] [Batch 320/836] [Loss: 0.1441]\n",
      "[Epoch 5/10] [Batch 330/836] [Loss: 0.2671]\n",
      "[Epoch 5/10] [Batch 340/836] [Loss: 0.2014]\n",
      "[Epoch 5/10] [Batch 350/836] [Loss: 0.2056]\n",
      "[Epoch 5/10] [Batch 360/836] [Loss: 0.0914]\n",
      "[Epoch 5/10] [Batch 370/836] [Loss: 0.2001]\n",
      "[Epoch 5/10] [Batch 380/836] [Loss: 0.2378]\n",
      "[Epoch 5/10] [Batch 390/836] [Loss: 0.2051]\n",
      "[Epoch 5/10] [Batch 400/836] [Loss: 0.1870]\n",
      "[Epoch 5/10] [Batch 410/836] [Loss: 0.0982]\n",
      "[Epoch 5/10] [Batch 420/836] [Loss: 0.3236]\n",
      "[Epoch 5/10] [Batch 430/836] [Loss: 0.1016]\n",
      "[Epoch 5/10] [Batch 440/836] [Loss: 0.2112]\n",
      "[Epoch 5/10] [Batch 450/836] [Loss: 0.0987]\n",
      "[Epoch 5/10] [Batch 460/836] [Loss: 0.0651]\n",
      "[Epoch 5/10] [Batch 470/836] [Loss: 0.2203]\n",
      "[Epoch 5/10] [Batch 480/836] [Loss: 0.2522]\n",
      "[Epoch 5/10] [Batch 490/836] [Loss: 0.0706]\n",
      "[Epoch 5/10] [Batch 500/836] [Loss: 0.2659]\n",
      "[Epoch 5/10] [Batch 510/836] [Loss: 0.2778]\n",
      "[Epoch 5/10] [Batch 520/836] [Loss: 0.1553]\n",
      "[Epoch 5/10] [Batch 530/836] [Loss: 0.0921]\n",
      "[Epoch 5/10] [Batch 540/836] [Loss: 0.1290]\n",
      "[Epoch 5/10] [Batch 550/836] [Loss: 0.1192]\n",
      "[Epoch 5/10] [Batch 560/836] [Loss: 0.0770]\n",
      "[Epoch 5/10] [Batch 570/836] [Loss: 0.1100]\n",
      "[Epoch 5/10] [Batch 580/836] [Loss: 0.0997]\n",
      "[Epoch 5/10] [Batch 590/836] [Loss: 0.3001]\n",
      "[Epoch 5/10] [Batch 600/836] [Loss: 0.0865]\n",
      "[Epoch 5/10] [Batch 610/836] [Loss: 0.1070]\n",
      "[Epoch 5/10] [Batch 620/836] [Loss: 0.0782]\n",
      "[Epoch 5/10] [Batch 630/836] [Loss: 0.2940]\n",
      "[Epoch 5/10] [Batch 640/836] [Loss: 0.1552]\n",
      "[Epoch 5/10] [Batch 650/836] [Loss: 0.0959]\n",
      "[Epoch 5/10] [Batch 660/836] [Loss: 0.0626]\n",
      "[Epoch 5/10] [Batch 670/836] [Loss: 0.0616]\n",
      "[Epoch 5/10] [Batch 680/836] [Loss: 0.0846]\n",
      "[Epoch 5/10] [Batch 690/836] [Loss: 0.2008]\n",
      "[Epoch 5/10] [Batch 700/836] [Loss: 0.2399]\n",
      "[Epoch 5/10] [Batch 710/836] [Loss: 0.2898]\n",
      "[Epoch 5/10] [Batch 720/836] [Loss: 0.1494]\n",
      "[Epoch 5/10] [Batch 730/836] [Loss: 0.1489]\n",
      "[Epoch 5/10] [Batch 740/836] [Loss: 0.2368]\n",
      "[Epoch 5/10] [Batch 750/836] [Loss: 0.1047]\n",
      "[Epoch 5/10] [Batch 760/836] [Loss: 0.1073]\n",
      "[Epoch 5/10] [Batch 770/836] [Loss: 0.2415]\n",
      "[Epoch 5/10] [Batch 780/836] [Loss: 0.3214]\n",
      "[Epoch 5/10] [Batch 790/836] [Loss: 0.0963]\n",
      "[Epoch 5/10] [Batch 800/836] [Loss: 0.0807]\n",
      "[Epoch 5/10] [Batch 810/836] [Loss: 0.1572]\n",
      "[Epoch 5/10] [Batch 820/836] [Loss: 0.0946]\n",
      "[Epoch 5/10] [Batch 830/836] [Loss: 0.2381]\n",
      "[Epoch 5/10] [Training Loss: 0.1682] [Time: 45.48s]\n",
      "[Epoch 5/10] [Validation Loss: 0.1757]\n",
      "[Epoch 6/10] [Batch 0/836] [Loss: 0.1709]\n",
      "[Epoch 6/10] [Batch 10/836] [Loss: 0.1680]\n",
      "[Epoch 6/10] [Batch 20/836] [Loss: 0.1714]\n",
      "[Epoch 6/10] [Batch 30/836] [Loss: 0.0615]\n",
      "[Epoch 6/10] [Batch 40/836] [Loss: 0.2274]\n",
      "[Epoch 6/10] [Batch 50/836] [Loss: 0.1643]\n",
      "[Epoch 6/10] [Batch 60/836] [Loss: 0.3223]\n",
      "[Epoch 6/10] [Batch 70/836] [Loss: 0.0941]\n",
      "[Epoch 6/10] [Batch 80/836] [Loss: 0.1273]\n",
      "[Epoch 6/10] [Batch 90/836] [Loss: 0.0515]\n",
      "[Epoch 6/10] [Batch 100/836] [Loss: 0.1221]\n",
      "[Epoch 6/10] [Batch 110/836] [Loss: 0.0832]\n",
      "[Epoch 6/10] [Batch 120/836] [Loss: 0.0856]\n",
      "[Epoch 6/10] [Batch 130/836] [Loss: 0.3700]\n",
      "[Epoch 6/10] [Batch 140/836] [Loss: 0.0743]\n",
      "[Epoch 6/10] [Batch 150/836] [Loss: 0.2638]\n",
      "[Epoch 6/10] [Batch 160/836] [Loss: 0.1594]\n",
      "[Epoch 6/10] [Batch 170/836] [Loss: 0.2180]\n",
      "[Epoch 6/10] [Batch 180/836] [Loss: 0.1549]\n",
      "[Epoch 6/10] [Batch 190/836] [Loss: 0.3008]\n",
      "[Epoch 6/10] [Batch 200/836] [Loss: 0.0965]\n",
      "[Epoch 6/10] [Batch 210/836] [Loss: 0.2170]\n",
      "[Epoch 6/10] [Batch 220/836] [Loss: 0.1120]\n",
      "[Epoch 6/10] [Batch 230/836] [Loss: 0.0930]\n",
      "[Epoch 6/10] [Batch 240/836] [Loss: 0.1300]\n",
      "[Epoch 6/10] [Batch 250/836] [Loss: 0.2716]\n",
      "[Epoch 6/10] [Batch 260/836] [Loss: 0.1641]\n",
      "[Epoch 6/10] [Batch 270/836] [Loss: 0.0909]\n",
      "[Epoch 6/10] [Batch 280/836] [Loss: 0.1439]\n",
      "[Epoch 6/10] [Batch 290/836] [Loss: 0.0656]\n",
      "[Epoch 6/10] [Batch 300/836] [Loss: 0.1287]\n",
      "[Epoch 6/10] [Batch 310/836] [Loss: 0.1152]\n",
      "[Epoch 6/10] [Batch 320/836] [Loss: 0.0787]\n",
      "[Epoch 6/10] [Batch 330/836] [Loss: 0.2788]\n",
      "[Epoch 6/10] [Batch 340/836] [Loss: 0.1638]\n",
      "[Epoch 6/10] [Batch 350/836] [Loss: 0.1524]\n",
      "[Epoch 6/10] [Batch 360/836] [Loss: 0.2518]\n",
      "[Epoch 6/10] [Batch 370/836] [Loss: 0.0789]\n",
      "[Epoch 6/10] [Batch 380/836] [Loss: 0.2673]\n",
      "[Epoch 6/10] [Batch 390/836] [Loss: 0.0817]\n",
      "[Epoch 6/10] [Batch 400/836] [Loss: 0.1049]\n",
      "[Epoch 6/10] [Batch 410/836] [Loss: 0.1003]\n",
      "[Epoch 6/10] [Batch 420/836] [Loss: 0.1371]\n",
      "[Epoch 6/10] [Batch 430/836] [Loss: 0.1838]\n",
      "[Epoch 6/10] [Batch 440/836] [Loss: 0.0844]\n",
      "[Epoch 6/10] [Batch 450/836] [Loss: 0.0514]\n",
      "[Epoch 6/10] [Batch 460/836] [Loss: 0.1148]\n",
      "[Epoch 6/10] [Batch 470/836] [Loss: 0.3039]\n",
      "[Epoch 6/10] [Batch 480/836] [Loss: 0.0900]\n",
      "[Epoch 6/10] [Batch 490/836] [Loss: 0.0740]\n",
      "[Epoch 6/10] [Batch 500/836] [Loss: 0.2279]\n",
      "[Epoch 6/10] [Batch 510/836] [Loss: 0.2647]\n",
      "[Epoch 6/10] [Batch 520/836] [Loss: 0.0902]\n",
      "[Epoch 6/10] [Batch 530/836] [Loss: 0.0983]\n",
      "[Epoch 6/10] [Batch 540/836] [Loss: 0.3084]\n",
      "[Epoch 6/10] [Batch 550/836] [Loss: 0.0707]\n",
      "[Epoch 6/10] [Batch 560/836] [Loss: 0.1143]\n",
      "[Epoch 6/10] [Batch 570/836] [Loss: 0.2185]\n",
      "[Epoch 6/10] [Batch 580/836] [Loss: 0.0937]\n",
      "[Epoch 6/10] [Batch 590/836] [Loss: 0.0837]\n",
      "[Epoch 6/10] [Batch 600/836] [Loss: 0.0549]\n",
      "[Epoch 6/10] [Batch 610/836] [Loss: 0.3042]\n",
      "[Epoch 6/10] [Batch 620/836] [Loss: 0.2204]\n",
      "[Epoch 6/10] [Batch 630/836] [Loss: 0.2087]\n",
      "[Epoch 6/10] [Batch 640/836] [Loss: 0.1554]\n",
      "[Epoch 6/10] [Batch 650/836] [Loss: 0.2527]\n",
      "[Epoch 6/10] [Batch 660/836] [Loss: 0.1985]\n",
      "[Epoch 6/10] [Batch 670/836] [Loss: 0.1613]\n",
      "[Epoch 6/10] [Batch 680/836] [Loss: 0.1205]\n",
      "[Epoch 6/10] [Batch 690/836] [Loss: 0.1217]\n",
      "[Epoch 6/10] [Batch 700/836] [Loss: 0.2611]\n",
      "[Epoch 6/10] [Batch 710/836] [Loss: 0.1279]\n",
      "[Epoch 6/10] [Batch 720/836] [Loss: 0.3114]\n",
      "[Epoch 6/10] [Batch 730/836] [Loss: 0.0995]\n",
      "[Epoch 6/10] [Batch 740/836] [Loss: 0.1148]\n",
      "[Epoch 6/10] [Batch 750/836] [Loss: 0.1316]\n",
      "[Epoch 6/10] [Batch 760/836] [Loss: 0.2714]\n",
      "[Epoch 6/10] [Batch 770/836] [Loss: 0.2478]\n",
      "[Epoch 6/10] [Batch 780/836] [Loss: 0.1454]\n",
      "[Epoch 6/10] [Batch 790/836] [Loss: 0.0930]\n",
      "[Epoch 6/10] [Batch 800/836] [Loss: 0.0821]\n",
      "[Epoch 6/10] [Batch 810/836] [Loss: 0.1617]\n",
      "[Epoch 6/10] [Batch 820/836] [Loss: 0.0713]\n",
      "[Epoch 6/10] [Batch 830/836] [Loss: 0.1333]\n",
      "[Epoch 6/10] [Training Loss: 0.1630] [Time: 47.03s]\n",
      "[Epoch 6/10] [Validation Loss: 0.1753]\n",
      "[Epoch 7/10] [Batch 0/836] [Loss: 0.2960]\n",
      "[Epoch 7/10] [Batch 10/836] [Loss: 0.1984]\n",
      "[Epoch 7/10] [Batch 20/836] [Loss: 0.0913]\n",
      "[Epoch 7/10] [Batch 30/836] [Loss: 0.1275]\n",
      "[Epoch 7/10] [Batch 40/836] [Loss: 0.1202]\n",
      "[Epoch 7/10] [Batch 50/836] [Loss: 0.2657]\n",
      "[Epoch 7/10] [Batch 60/836] [Loss: 0.2107]\n",
      "[Epoch 7/10] [Batch 70/836] [Loss: 0.1457]\n",
      "[Epoch 7/10] [Batch 80/836] [Loss: 0.1785]\n",
      "[Epoch 7/10] [Batch 90/836] [Loss: 0.1892]\n",
      "[Epoch 7/10] [Batch 100/836] [Loss: 0.3613]\n",
      "[Epoch 7/10] [Batch 110/836] [Loss: 0.2250]\n",
      "[Epoch 7/10] [Batch 120/836] [Loss: 0.1759]\n",
      "[Epoch 7/10] [Batch 130/836] [Loss: 0.0802]\n",
      "[Epoch 7/10] [Batch 140/836] [Loss: 0.0582]\n",
      "[Epoch 7/10] [Batch 150/836] [Loss: 0.1676]\n",
      "[Epoch 7/10] [Batch 160/836] [Loss: 0.2447]\n",
      "[Epoch 7/10] [Batch 170/836] [Loss: 0.3588]\n",
      "[Epoch 7/10] [Batch 180/836] [Loss: 0.2429]\n",
      "[Epoch 7/10] [Batch 190/836] [Loss: 0.0921]\n",
      "[Epoch 7/10] [Batch 200/836] [Loss: 0.1260]\n",
      "[Epoch 7/10] [Batch 210/836] [Loss: 0.1341]\n",
      "[Epoch 7/10] [Batch 220/836] [Loss: 0.0865]\n",
      "[Epoch 7/10] [Batch 230/836] [Loss: 0.1652]\n",
      "[Epoch 7/10] [Batch 240/836] [Loss: 0.1382]\n",
      "[Epoch 7/10] [Batch 250/836] [Loss: 0.2977]\n",
      "[Epoch 7/10] [Batch 260/836] [Loss: 0.1083]\n",
      "[Epoch 7/10] [Batch 270/836] [Loss: 0.2721]\n",
      "[Epoch 7/10] [Batch 280/836] [Loss: 0.1137]\n",
      "[Epoch 7/10] [Batch 290/836] [Loss: 0.1608]\n",
      "[Epoch 7/10] [Batch 300/836] [Loss: 0.1156]\n",
      "[Epoch 7/10] [Batch 310/836] [Loss: 0.2036]\n",
      "[Epoch 7/10] [Batch 320/836] [Loss: 0.1353]\n",
      "[Epoch 7/10] [Batch 330/836] [Loss: 0.1692]\n",
      "[Epoch 7/10] [Batch 340/836] [Loss: 0.0899]\n",
      "[Epoch 7/10] [Batch 350/836] [Loss: 0.0621]\n",
      "[Epoch 7/10] [Batch 360/836] [Loss: 0.1916]\n",
      "[Epoch 7/10] [Batch 370/836] [Loss: 0.0756]\n",
      "[Epoch 7/10] [Batch 380/836] [Loss: 0.1144]\n",
      "[Epoch 7/10] [Batch 390/836] [Loss: 0.1180]\n",
      "[Epoch 7/10] [Batch 400/836] [Loss: 0.1721]\n",
      "[Epoch 7/10] [Batch 410/836] [Loss: 0.1048]\n",
      "[Epoch 7/10] [Batch 420/836] [Loss: 0.0866]\n",
      "[Epoch 7/10] [Batch 430/836] [Loss: 0.0700]\n",
      "[Epoch 7/10] [Batch 440/836] [Loss: 0.1313]\n",
      "[Epoch 7/10] [Batch 450/836] [Loss: 0.2331]\n",
      "[Epoch 7/10] [Batch 460/836] [Loss: 0.1697]\n",
      "[Epoch 7/10] [Batch 470/836] [Loss: 0.1843]\n",
      "[Epoch 7/10] [Batch 480/836] [Loss: 0.3365]\n",
      "[Epoch 7/10] [Batch 490/836] [Loss: 0.0956]\n",
      "[Epoch 7/10] [Batch 500/836] [Loss: 0.0932]\n",
      "[Epoch 7/10] [Batch 510/836] [Loss: 0.2228]\n",
      "[Epoch 7/10] [Batch 520/836] [Loss: 0.1851]\n",
      "[Epoch 7/10] [Batch 530/836] [Loss: 0.1066]\n",
      "[Epoch 7/10] [Batch 540/836] [Loss: 0.0743]\n",
      "[Epoch 7/10] [Batch 550/836] [Loss: 0.1465]\n",
      "[Epoch 7/10] [Batch 560/836] [Loss: 0.1290]\n",
      "[Epoch 7/10] [Batch 570/836] [Loss: 0.1626]\n",
      "[Epoch 7/10] [Batch 580/836] [Loss: 0.1534]\n",
      "[Epoch 7/10] [Batch 590/836] [Loss: 0.0879]\n",
      "[Epoch 7/10] [Batch 600/836] [Loss: 0.1902]\n",
      "[Epoch 7/10] [Batch 610/836] [Loss: 0.1860]\n",
      "[Epoch 7/10] [Batch 620/836] [Loss: 0.2842]\n",
      "[Epoch 7/10] [Batch 630/836] [Loss: 0.1551]\n",
      "[Epoch 7/10] [Batch 640/836] [Loss: 0.1932]\n",
      "[Epoch 7/10] [Batch 650/836] [Loss: 0.2131]\n",
      "[Epoch 7/10] [Batch 660/836] [Loss: 0.3752]\n",
      "[Epoch 7/10] [Batch 670/836] [Loss: 0.1747]\n",
      "[Epoch 7/10] [Batch 680/836] [Loss: 0.1496]\n",
      "[Epoch 7/10] [Batch 690/836] [Loss: 0.0862]\n",
      "[Epoch 7/10] [Batch 700/836] [Loss: 0.2117]\n",
      "[Epoch 7/10] [Batch 710/836] [Loss: 0.1174]\n",
      "[Epoch 7/10] [Batch 720/836] [Loss: 0.1658]\n",
      "[Epoch 7/10] [Batch 730/836] [Loss: 0.1168]\n",
      "[Epoch 7/10] [Batch 740/836] [Loss: 0.3172]\n",
      "[Epoch 7/10] [Batch 750/836] [Loss: 0.2376]\n",
      "[Epoch 7/10] [Batch 760/836] [Loss: 0.1185]\n",
      "[Epoch 7/10] [Batch 770/836] [Loss: 0.0915]\n",
      "[Epoch 7/10] [Batch 780/836] [Loss: 0.1015]\n",
      "[Epoch 7/10] [Batch 790/836] [Loss: 0.2859]\n",
      "[Epoch 7/10] [Batch 800/836] [Loss: 0.1085]\n",
      "[Epoch 7/10] [Batch 810/836] [Loss: 0.2977]\n",
      "[Epoch 7/10] [Batch 820/836] [Loss: 0.2556]\n",
      "[Epoch 7/10] [Batch 830/836] [Loss: 0.0725]\n",
      "[Epoch 7/10] [Training Loss: 0.1510] [Time: 45.06s]\n",
      "[Epoch 7/10] [Validation Loss: 0.1743]\n",
      "[Epoch 8/10] [Batch 0/836] [Loss: 0.1048]\n",
      "[Epoch 8/10] [Batch 10/836] [Loss: 0.2111]\n",
      "[Epoch 8/10] [Batch 20/836] [Loss: 0.1881]\n",
      "[Epoch 8/10] [Batch 30/836] [Loss: 0.1080]\n",
      "[Epoch 8/10] [Batch 40/836] [Loss: 0.1398]\n",
      "[Epoch 8/10] [Batch 50/836] [Loss: 0.1494]\n",
      "[Epoch 8/10] [Batch 60/836] [Loss: 0.1662]\n",
      "[Epoch 8/10] [Batch 70/836] [Loss: 0.2793]\n",
      "[Epoch 8/10] [Batch 80/836] [Loss: 0.1370]\n",
      "[Epoch 8/10] [Batch 90/836] [Loss: 0.0957]\n",
      "[Epoch 8/10] [Batch 100/836] [Loss: 0.1162]\n",
      "[Epoch 8/10] [Batch 110/836] [Loss: 0.0816]\n",
      "[Epoch 8/10] [Batch 120/836] [Loss: 0.2872]\n",
      "[Epoch 8/10] [Batch 130/836] [Loss: 0.1265]\n",
      "[Epoch 8/10] [Batch 140/836] [Loss: 0.1999]\n",
      "[Epoch 8/10] [Batch 150/836] [Loss: 0.0747]\n",
      "[Epoch 8/10] [Batch 160/836] [Loss: 0.1299]\n",
      "[Epoch 8/10] [Batch 170/836] [Loss: 0.0884]\n",
      "[Epoch 8/10] [Batch 180/836] [Loss: 0.0801]\n",
      "[Epoch 8/10] [Batch 190/836] [Loss: 0.3550]\n",
      "[Epoch 8/10] [Batch 200/836] [Loss: 0.2941]\n",
      "[Epoch 8/10] [Batch 210/836] [Loss: 0.0548]\n",
      "[Epoch 8/10] [Batch 220/836] [Loss: 0.2488]\n",
      "[Epoch 8/10] [Batch 230/836] [Loss: 0.0756]\n",
      "[Epoch 8/10] [Batch 240/836] [Loss: 0.0611]\n",
      "[Epoch 8/10] [Batch 250/836] [Loss: 0.1798]\n",
      "[Epoch 8/10] [Batch 260/836] [Loss: 0.1650]\n",
      "[Epoch 8/10] [Batch 270/836] [Loss: 0.2038]\n",
      "[Epoch 8/10] [Batch 280/836] [Loss: 0.0702]\n",
      "[Epoch 8/10] [Batch 290/836] [Loss: 0.1779]\n",
      "[Epoch 8/10] [Batch 300/836] [Loss: 0.0735]\n",
      "[Epoch 8/10] [Batch 310/836] [Loss: 0.0594]\n",
      "[Epoch 8/10] [Batch 320/836] [Loss: 0.1029]\n",
      "[Epoch 8/10] [Batch 330/836] [Loss: 0.0534]\n",
      "[Epoch 8/10] [Batch 340/836] [Loss: 0.2402]\n",
      "[Epoch 8/10] [Batch 350/836] [Loss: 0.1330]\n",
      "[Epoch 8/10] [Batch 360/836] [Loss: 0.0753]\n",
      "[Epoch 8/10] [Batch 370/836] [Loss: 0.1354]\n",
      "[Epoch 8/10] [Batch 380/836] [Loss: 0.2931]\n",
      "[Epoch 8/10] [Batch 390/836] [Loss: 0.1062]\n",
      "[Epoch 8/10] [Batch 400/836] [Loss: 0.1831]\n",
      "[Epoch 8/10] [Batch 410/836] [Loss: 0.1180]\n",
      "[Epoch 8/10] [Batch 420/836] [Loss: 0.2680]\n",
      "[Epoch 8/10] [Batch 430/836] [Loss: 0.2501]\n",
      "[Epoch 8/10] [Batch 440/836] [Loss: 0.1519]\n",
      "[Epoch 8/10] [Batch 450/836] [Loss: 0.1849]\n",
      "[Epoch 8/10] [Batch 460/836] [Loss: 0.1370]\n",
      "[Epoch 8/10] [Batch 470/836] [Loss: 0.2298]\n",
      "[Epoch 8/10] [Batch 480/836] [Loss: 0.1591]\n",
      "[Epoch 8/10] [Batch 490/836] [Loss: 0.1641]\n",
      "[Epoch 8/10] [Batch 500/836] [Loss: 0.0674]\n",
      "[Epoch 8/10] [Batch 510/836] [Loss: 0.1572]\n",
      "[Epoch 8/10] [Batch 520/836] [Loss: 0.3116]\n",
      "[Epoch 8/10] [Batch 530/836] [Loss: 0.1037]\n",
      "[Epoch 8/10] [Batch 540/836] [Loss: 0.2224]\n",
      "[Epoch 8/10] [Batch 550/836] [Loss: 0.1358]\n",
      "[Epoch 8/10] [Batch 560/836] [Loss: 0.3537]\n",
      "[Epoch 8/10] [Batch 570/836] [Loss: 0.2439]\n",
      "[Epoch 8/10] [Batch 580/836] [Loss: 0.0475]\n",
      "[Epoch 8/10] [Batch 590/836] [Loss: 0.0804]\n",
      "[Epoch 8/10] [Batch 600/836] [Loss: 0.1091]\n",
      "[Epoch 8/10] [Batch 610/836] [Loss: 0.0491]\n",
      "[Epoch 8/10] [Batch 620/836] [Loss: 0.0575]\n",
      "[Epoch 8/10] [Batch 630/836] [Loss: 0.1484]\n",
      "[Epoch 8/10] [Batch 640/836] [Loss: 0.0606]\n",
      "[Epoch 8/10] [Batch 650/836] [Loss: 0.0858]\n",
      "[Epoch 8/10] [Batch 660/836] [Loss: 0.2492]\n",
      "[Epoch 8/10] [Batch 670/836] [Loss: 0.1618]\n",
      "[Epoch 8/10] [Batch 680/836] [Loss: 0.0503]\n",
      "[Epoch 8/10] [Batch 690/836] [Loss: 0.0702]\n",
      "[Epoch 8/10] [Batch 700/836] [Loss: 0.0933]\n",
      "[Epoch 8/10] [Batch 710/836] [Loss: 0.1334]\n",
      "[Epoch 8/10] [Batch 720/836] [Loss: 0.0659]\n",
      "[Epoch 8/10] [Batch 730/836] [Loss: 0.1010]\n",
      "[Epoch 8/10] [Batch 740/836] [Loss: 0.3733]\n",
      "[Epoch 8/10] [Batch 750/836] [Loss: 0.2253]\n",
      "[Epoch 8/10] [Batch 760/836] [Loss: 0.0880]\n",
      "[Epoch 8/10] [Batch 770/836] [Loss: 0.1119]\n",
      "[Epoch 8/10] [Batch 780/836] [Loss: 0.1771]\n",
      "[Epoch 8/10] [Batch 790/836] [Loss: 0.2285]\n",
      "[Epoch 8/10] [Batch 800/836] [Loss: 0.0762]\n",
      "[Epoch 8/10] [Batch 810/836] [Loss: 0.0821]\n",
      "[Epoch 8/10] [Batch 820/836] [Loss: 0.1689]\n",
      "[Epoch 8/10] [Batch 830/836] [Loss: 0.2559]\n",
      "[Epoch 8/10] [Training Loss: 0.1449] [Time: 45.24s]\n",
      "[Epoch 8/10] [Validation Loss: 0.1726]\n",
      "[Epoch 9/10] [Batch 0/836] [Loss: 0.1870]\n",
      "[Epoch 9/10] [Batch 10/836] [Loss: 0.0601]\n",
      "[Epoch 9/10] [Batch 20/836] [Loss: 0.2488]\n",
      "[Epoch 9/10] [Batch 30/836] [Loss: 0.0645]\n",
      "[Epoch 9/10] [Batch 40/836] [Loss: 0.1622]\n",
      "[Epoch 9/10] [Batch 50/836] [Loss: 0.2588]\n",
      "[Epoch 9/10] [Batch 60/836] [Loss: 0.0637]\n",
      "[Epoch 9/10] [Batch 70/836] [Loss: 0.1051]\n",
      "[Epoch 9/10] [Batch 80/836] [Loss: 0.0856]\n",
      "[Epoch 9/10] [Batch 90/836] [Loss: 0.2675]\n",
      "[Epoch 9/10] [Batch 100/836] [Loss: 0.2433]\n",
      "[Epoch 9/10] [Batch 110/836] [Loss: 0.1161]\n",
      "[Epoch 9/10] [Batch 120/836] [Loss: 0.2429]\n",
      "[Epoch 9/10] [Batch 130/836] [Loss: 0.1296]\n",
      "[Epoch 9/10] [Batch 140/836] [Loss: 0.1804]\n",
      "[Epoch 9/10] [Batch 150/836] [Loss: 0.3423]\n",
      "[Epoch 9/10] [Batch 160/836] [Loss: 0.1646]\n",
      "[Epoch 9/10] [Batch 170/836] [Loss: 0.0861]\n",
      "[Epoch 9/10] [Batch 180/836] [Loss: 0.1291]\n",
      "[Epoch 9/10] [Batch 190/836] [Loss: 0.2965]\n",
      "[Epoch 9/10] [Batch 200/836] [Loss: 0.1719]\n",
      "[Epoch 9/10] [Batch 210/836] [Loss: 0.0668]\n",
      "[Epoch 9/10] [Batch 220/836] [Loss: 0.1911]\n",
      "[Epoch 9/10] [Batch 230/836] [Loss: 0.0701]\n",
      "[Epoch 9/10] [Batch 240/836] [Loss: 0.3493]\n",
      "[Epoch 9/10] [Batch 250/836] [Loss: 0.0758]\n",
      "[Epoch 9/10] [Batch 260/836] [Loss: 0.0868]\n",
      "[Epoch 9/10] [Batch 270/836] [Loss: 0.2209]\n",
      "[Epoch 9/10] [Batch 280/836] [Loss: 0.0826]\n",
      "[Epoch 9/10] [Batch 290/836] [Loss: 0.0759]\n",
      "[Epoch 9/10] [Batch 300/836] [Loss: 0.1243]\n",
      "[Epoch 9/10] [Batch 310/836] [Loss: 0.0891]\n",
      "[Epoch 9/10] [Batch 320/836] [Loss: 0.1420]\n",
      "[Epoch 9/10] [Batch 330/836] [Loss: 0.1031]\n",
      "[Epoch 9/10] [Batch 340/836] [Loss: 0.0952]\n",
      "[Epoch 9/10] [Batch 350/836] [Loss: 0.2134]\n",
      "[Epoch 9/10] [Batch 360/836] [Loss: 0.2963]\n",
      "[Epoch 9/10] [Batch 370/836] [Loss: 0.1258]\n",
      "[Epoch 9/10] [Batch 380/836] [Loss: 0.2941]\n",
      "[Epoch 9/10] [Batch 390/836] [Loss: 0.0930]\n",
      "[Epoch 9/10] [Batch 400/836] [Loss: 0.3005]\n",
      "[Epoch 9/10] [Batch 410/836] [Loss: 0.2032]\n",
      "[Epoch 9/10] [Batch 420/836] [Loss: 0.0707]\n",
      "[Epoch 9/10] [Batch 430/836] [Loss: 0.0850]\n",
      "[Epoch 9/10] [Batch 440/836] [Loss: 0.2336]\n",
      "[Epoch 9/10] [Batch 450/836] [Loss: 0.0985]\n",
      "[Epoch 9/10] [Batch 460/836] [Loss: 0.1184]\n",
      "[Epoch 9/10] [Batch 470/836] [Loss: 0.2822]\n",
      "[Epoch 9/10] [Batch 480/836] [Loss: 0.1001]\n",
      "[Epoch 9/10] [Batch 490/836] [Loss: 0.1082]\n",
      "[Epoch 9/10] [Batch 500/836] [Loss: 0.0761]\n",
      "[Epoch 9/10] [Batch 510/836] [Loss: 0.1361]\n",
      "[Epoch 9/10] [Batch 520/836] [Loss: 0.1641]\n",
      "[Epoch 9/10] [Batch 530/836] [Loss: 0.1242]\n",
      "[Epoch 9/10] [Batch 540/836] [Loss: 0.1560]\n",
      "[Epoch 9/10] [Batch 550/836] [Loss: 0.1926]\n",
      "[Epoch 9/10] [Batch 560/836] [Loss: 0.1371]\n",
      "[Epoch 9/10] [Batch 570/836] [Loss: 0.1800]\n",
      "[Epoch 9/10] [Batch 580/836] [Loss: 0.2067]\n",
      "[Epoch 9/10] [Batch 590/836] [Loss: 0.1688]\n",
      "[Epoch 9/10] [Batch 600/836] [Loss: 0.1723]\n",
      "[Epoch 9/10] [Batch 610/836] [Loss: 0.2358]\n",
      "[Epoch 9/10] [Batch 620/836] [Loss: 0.1700]\n",
      "[Epoch 9/10] [Batch 630/836] [Loss: 0.0834]\n",
      "[Epoch 9/10] [Batch 640/836] [Loss: 0.1903]\n",
      "[Epoch 9/10] [Batch 650/836] [Loss: 0.0485]\n",
      "[Epoch 9/10] [Batch 660/836] [Loss: 0.1098]\n",
      "[Epoch 9/10] [Batch 670/836] [Loss: 0.1094]\n",
      "[Epoch 9/10] [Batch 680/836] [Loss: 0.1120]\n",
      "[Epoch 9/10] [Batch 690/836] [Loss: 0.2302]\n",
      "[Epoch 9/10] [Batch 700/836] [Loss: 0.2003]\n",
      "[Epoch 9/10] [Batch 710/836] [Loss: 0.0473]\n",
      "[Epoch 9/10] [Batch 720/836] [Loss: 0.0876]\n",
      "[Epoch 9/10] [Batch 730/836] [Loss: 0.0670]\n",
      "[Epoch 9/10] [Batch 740/836] [Loss: 0.1120]\n",
      "[Epoch 9/10] [Batch 750/836] [Loss: 0.1359]\n",
      "[Epoch 9/10] [Batch 760/836] [Loss: 0.1564]\n",
      "[Epoch 9/10] [Batch 770/836] [Loss: 0.1544]\n",
      "[Epoch 9/10] [Batch 780/836] [Loss: 0.1533]\n",
      "[Epoch 9/10] [Batch 790/836] [Loss: 0.2208]\n",
      "[Epoch 9/10] [Batch 800/836] [Loss: 0.2095]\n",
      "[Epoch 9/10] [Batch 810/836] [Loss: 0.1011]\n",
      "[Epoch 9/10] [Batch 820/836] [Loss: 0.0915]\n",
      "[Epoch 9/10] [Batch 830/836] [Loss: 0.0836]\n",
      "[Epoch 9/10] [Training Loss: 0.1506] [Time: 44.84s]\n",
      "[Epoch 9/10] [Validation Loss: 0.1740]\n",
      "[Epoch 10/10] [Batch 0/836] [Loss: 0.1228]\n",
      "[Epoch 10/10] [Batch 10/836] [Loss: 0.0494]\n",
      "[Epoch 10/10] [Batch 20/836] [Loss: 0.0963]\n",
      "[Epoch 10/10] [Batch 30/836] [Loss: 0.1090]\n",
      "[Epoch 10/10] [Batch 40/836] [Loss: 0.1995]\n",
      "[Epoch 10/10] [Batch 50/836] [Loss: 0.2626]\n",
      "[Epoch 10/10] [Batch 60/836] [Loss: 0.1273]\n",
      "[Epoch 10/10] [Batch 70/836] [Loss: 0.1555]\n",
      "[Epoch 10/10] [Batch 80/836] [Loss: 0.1181]\n",
      "[Epoch 10/10] [Batch 90/836] [Loss: 0.2480]\n",
      "[Epoch 10/10] [Batch 100/836] [Loss: 0.1467]\n",
      "[Epoch 10/10] [Batch 110/836] [Loss: 0.0576]\n",
      "[Epoch 10/10] [Batch 120/836] [Loss: 0.0951]\n",
      "[Epoch 10/10] [Batch 130/836] [Loss: 0.1636]\n",
      "[Epoch 10/10] [Batch 140/836] [Loss: 0.0555]\n",
      "[Epoch 10/10] [Batch 150/836] [Loss: 0.0951]\n",
      "[Epoch 10/10] [Batch 160/836] [Loss: 0.2933]\n",
      "[Epoch 10/10] [Batch 170/836] [Loss: 0.1892]\n",
      "[Epoch 10/10] [Batch 180/836] [Loss: 0.3566]\n",
      "[Epoch 10/10] [Batch 190/836] [Loss: 0.1097]\n",
      "[Epoch 10/10] [Batch 200/836] [Loss: 0.1617]\n",
      "[Epoch 10/10] [Batch 210/836] [Loss: 0.0718]\n",
      "[Epoch 10/10] [Batch 220/836] [Loss: 0.2175]\n",
      "[Epoch 10/10] [Batch 230/836] [Loss: 0.1400]\n",
      "[Epoch 10/10] [Batch 240/836] [Loss: 0.1087]\n",
      "[Epoch 10/10] [Batch 250/836] [Loss: 0.1408]\n",
      "[Epoch 10/10] [Batch 260/836] [Loss: 0.0987]\n",
      "[Epoch 10/10] [Batch 270/836] [Loss: 0.1047]\n",
      "[Epoch 10/10] [Batch 280/836] [Loss: 0.1399]\n",
      "[Epoch 10/10] [Batch 290/836] [Loss: 0.0903]\n",
      "[Epoch 10/10] [Batch 300/836] [Loss: 0.2639]\n",
      "[Epoch 10/10] [Batch 310/836] [Loss: 0.1796]\n",
      "[Epoch 10/10] [Batch 320/836] [Loss: 0.1739]\n",
      "[Epoch 10/10] [Batch 330/836] [Loss: 0.1673]\n",
      "[Epoch 10/10] [Batch 340/836] [Loss: 0.1903]\n",
      "[Epoch 10/10] [Batch 350/836] [Loss: 0.1343]\n",
      "[Epoch 10/10] [Batch 360/836] [Loss: 0.0452]\n",
      "[Epoch 10/10] [Batch 370/836] [Loss: 0.1486]\n",
      "[Epoch 10/10] [Batch 380/836] [Loss: 0.1285]\n",
      "[Epoch 10/10] [Batch 390/836] [Loss: 0.2539]\n",
      "[Epoch 10/10] [Batch 400/836] [Loss: 0.1475]\n",
      "[Epoch 10/10] [Batch 410/836] [Loss: 0.1629]\n",
      "[Epoch 10/10] [Batch 420/836] [Loss: 0.0749]\n",
      "[Epoch 10/10] [Batch 430/836] [Loss: 0.1212]\n",
      "[Epoch 10/10] [Batch 440/836] [Loss: 0.0941]\n",
      "[Epoch 10/10] [Batch 450/836] [Loss: 0.2583]\n",
      "[Epoch 10/10] [Batch 460/836] [Loss: 0.1259]\n",
      "[Epoch 10/10] [Batch 470/836] [Loss: 0.0650]\n",
      "[Epoch 10/10] [Batch 480/836] [Loss: 0.1215]\n",
      "[Epoch 10/10] [Batch 490/836] [Loss: 0.2179]\n",
      "[Epoch 10/10] [Batch 500/836] [Loss: 0.0808]\n",
      "[Epoch 10/10] [Batch 510/836] [Loss: 0.1444]\n",
      "[Epoch 10/10] [Batch 520/836] [Loss: 0.1030]\n",
      "[Epoch 10/10] [Batch 530/836] [Loss: 0.0462]\n",
      "[Epoch 10/10] [Batch 540/836] [Loss: 0.1524]\n",
      "[Epoch 10/10] [Batch 550/836] [Loss: 0.0895]\n",
      "[Epoch 10/10] [Batch 560/836] [Loss: 0.2866]\n",
      "[Epoch 10/10] [Batch 570/836] [Loss: 0.1601]\n",
      "[Epoch 10/10] [Batch 580/836] [Loss: 0.1066]\n",
      "[Epoch 10/10] [Batch 590/836] [Loss: 0.0750]\n",
      "[Epoch 10/10] [Batch 600/836] [Loss: 0.2757]\n",
      "[Epoch 10/10] [Batch 610/836] [Loss: 0.0492]\n",
      "[Epoch 10/10] [Batch 620/836] [Loss: 0.3150]\n",
      "[Epoch 10/10] [Batch 630/836] [Loss: 0.2469]\n",
      "[Epoch 10/10] [Batch 640/836] [Loss: 0.1396]\n",
      "[Epoch 10/10] [Batch 650/836] [Loss: 0.0430]\n",
      "[Epoch 10/10] [Batch 660/836] [Loss: 0.1776]\n",
      "[Epoch 10/10] [Batch 670/836] [Loss: 0.0952]\n",
      "[Epoch 10/10] [Batch 680/836] [Loss: 0.1928]\n",
      "[Epoch 10/10] [Batch 690/836] [Loss: 0.1094]\n",
      "[Epoch 10/10] [Batch 700/836] [Loss: 0.1553]\n",
      "[Epoch 10/10] [Batch 710/836] [Loss: 0.0623]\n",
      "[Epoch 10/10] [Batch 720/836] [Loss: 0.1000]\n",
      "[Epoch 10/10] [Batch 730/836] [Loss: 0.0555]\n",
      "[Epoch 10/10] [Batch 740/836] [Loss: 0.0668]\n",
      "[Epoch 10/10] [Batch 750/836] [Loss: 0.0860]\n",
      "[Epoch 10/10] [Batch 760/836] [Loss: 0.1167]\n",
      "[Epoch 10/10] [Batch 770/836] [Loss: 0.1300]\n",
      "[Epoch 10/10] [Batch 780/836] [Loss: 0.1937]\n",
      "[Epoch 10/10] [Batch 790/836] [Loss: 0.1035]\n",
      "[Epoch 10/10] [Batch 800/836] [Loss: 0.1160]\n",
      "[Epoch 10/10] [Batch 810/836] [Loss: 0.1301]\n",
      "[Epoch 10/10] [Batch 820/836] [Loss: 0.1527]\n",
      "[Epoch 10/10] [Batch 830/836] [Loss: 0.1068]\n",
      "[Epoch 10/10] [Training Loss: 0.1514] [Time: 45.08s]\n",
      "[Epoch 10/10] [Validation Loss: 0.1735]\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"[Epoch {epoch + 1}/{num_epochs}] [Batch {i}/{len(train_loader)}] [Loss: {losses.item():.4f}]\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f\"[Epoch {epoch + 1}/{num_epochs}] [Training Loss: {epoch_loss:.4f}] [Time: {time.time() - start_time:.2f}s]\")\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Evaluate on the validation dataset\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Compute validation loss in training mode\n",
    "            model.train()  # Temporarily set the model to training mode\n",
    "            loss_dict = model(images, targets)\n",
    "            model.eval()  # Set the model back to evaluation mode\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"[Epoch {epoch + 1}/{num_epochs}] [Validation Loss: {val_loss:.4f}]\")\n",
    "\n",
    "print(\"Training complete.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:24:21.197398Z",
     "start_time": "2024-07-28T21:16:41.771984Z"
    }
   },
   "id": "68fd4d177c6821e1"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Save the model and optimizer state dictionaries\n",
    "def save_model(model, optimizer, epoch, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "# Example usage\n",
    "save_model(model, optimizer, epoch, 'best_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T03:30:02.303804Z",
     "start_time": "2024-07-28T03:30:01.080485Z"
    }
   },
   "id": "c037051839737028"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Load the model and optimizer state dictionaries\n",
    "def load_model(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    return model, optimizer, epoch\n",
    "\n",
    "num_classes = 2 \n",
    "model = get_model(num_classes)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model, optimizer, start_epoch = load_model(model, optimizer, 'best_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:27:37.933094Z",
     "start_time": "2024-07-28T21:27:36.258896Z"
    }
   },
   "id": "54e6872674166e48"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1:\n",
      "  No high-confidence predicted boxes found\n",
      "Image 1:\n",
      "  Predicted box with highest score: [172.00107 302.46927 214.35689 324.21185]\n",
      "  Ground truth boxes: [[176. 306. 215. 323.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [291.11615 348.30753 340.0936  379.49042]\n",
      "  Ground truth boxes: [[238. 258. 262. 283.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [246.11296 258.90988 272.60245 283.13385]\n",
      "  Ground truth boxes: [[250. 258. 274. 283.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [252.66254 131.24977 298.79187 167.00879]\n",
      "  Ground truth boxes: [[295. 145. 311. 170.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [205.41316 127.02197 261.91418 164.65137]\n",
      "  Ground truth boxes: [[201. 145. 217. 170.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [273.4343  280.74384 319.25516 317.1421 ]\n",
      "  Ground truth boxes: [[208. 293. 273. 336.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [192.20212 282.77133 240.65709 318.27585]\n",
      "  Ground truth boxes: [[239. 293. 304. 336.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [293.59323 302.8606  364.7823  341.47046]\n",
      "  Ground truth boxes: [[311. 312. 363. 344.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [146.85236 302.8703  221.0842  337.87753]\n",
      "  Ground truth boxes: [[149. 312. 201. 344.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [282.45602 142.59183 331.85425 175.2994 ]\n",
      "  Ground truth boxes: [[293. 221. 311. 248.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [179.30959 141.20409 230.12411 170.408  ]\n",
      "  Ground truth boxes: [[201. 221. 219. 248.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [266.15897 146.99786 317.4514  181.13643]\n",
      "  Ground truth boxes: [[271. 228. 297. 258.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [193.56282 149.57489 234.31161 181.51035]\n",
      "  Ground truth boxes: [[215. 228. 241. 258.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [186.24341 173.9805  208.3151  196.45598]\n",
      "  Ground truth boxes: [[244. 240. 263. 271.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [196.8386  161.63364 217.2355  194.90765]\n",
      "  Ground truth boxes: [[249. 240. 268. 271.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [206.76433 171.80498 241.24593 203.13165]\n",
      "  Ground truth boxes: [[205. 239. 220. 261.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [274.99927 171.94421 305.16956 205.29976]\n",
      "  Ground truth boxes: [[292. 239. 307. 261.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [308.33868 262.43777 369.98007 293.1598 ]\n",
      "  Ground truth boxes: [[275. 284. 308. 299.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [220.2516  342.9759  251.39636 363.6949 ]\n",
      "  Ground truth boxes: [[204. 284. 237. 299.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [224.38892 250.06538 250.35783 288.54883]\n",
      "  Ground truth boxes: [[225. 278. 256. 296.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [254.67203 252.67763 286.89725 285.7127 ]\n",
      "  Ground truth boxes: [[256. 278. 287. 296.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [302.70413 186.90068 326.54547 272.1372 ]\n",
      "  Ground truth boxes: [[301. 197. 323. 221.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [184.71056 194.71753 213.23193 245.06293]\n",
      "  Ground truth boxes: [[189. 197. 211. 221.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [246.87103 141.47272 329.0553  356.44644]\n",
      "  Ground truth boxes: [[251. 215. 347. 354.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [179.35214 134.66415 265.60144 347.32288]\n",
      "  Ground truth boxes: [[165. 215. 261. 354.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [289.12512 181.07047 339.92865 212.63261]\n",
      "  Ground truth boxes: [[303. 180. 344. 214.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [174.345   176.3089  220.30016 209.59152]\n",
      "  Ground truth boxes: [[168. 180. 209. 214.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [125.98269 171.84343 155.48396 195.77121]\n",
      "  Ground truth boxes: [[123. 172. 164. 199.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [354.1518  174.32562 387.88217 195.46956]\n",
      "  Ground truth boxes: [[348. 172. 389. 199.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [159.0939  174.34712 201.48445 218.0715 ]\n",
      "  Ground truth boxes: [[167. 177. 203. 200.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [309.95892 171.8409  347.49707 203.1182 ]\n",
      "  Ground truth boxes: [[309. 177. 345. 200.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [172.22351 190.53134 208.4614  217.79509]\n",
      "  Ground truth boxes: [[170. 195. 210. 222.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [302.99426 191.40291 338.76913 221.59407]\n",
      "  Ground truth boxes: [[302. 195. 342. 222.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [256.26013 159.86285 305.8853  189.18663]\n",
      "  Ground truth boxes: [[260. 162. 303. 184.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [208.1431  160.56396 254.82396 188.13167]\n",
      "  Ground truth boxes: [[209. 162. 252. 184.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [251.28906 161.20105 300.38586 190.08176]\n",
      "  Ground truth boxes: [[251. 164. 296. 187.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [212.43675 161.97386 259.7878  188.21805]\n",
      "  Ground truth boxes: [[216. 164. 261. 187.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [252.6124  218.60605 272.15756 252.65004]\n",
      "  Ground truth boxes: [[253. 221. 271. 253.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [240.10042 219.82243 258.70547 250.42197]\n",
      "  Ground truth boxes: [[241. 221. 259. 253.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [174.8804  275.61362 193.13806 295.376  ]\n",
      "  Ground truth boxes: [[170. 272. 190. 293.]]\n",
      "Image 1:\n",
      "  No high-confidence predicted boxes found\n",
      "Image 1:\n",
      "  Predicted box with highest score: [205.5744  159.67096 248.0143  220.47531]\n",
      "  Ground truth boxes: [[205. 181. 248. 228.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [265.57053 160.12082 306.6186  217.5439 ]\n",
      "  Ground truth boxes: [[264. 181. 307. 228.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [323.21832 197.5918  396.43988 261.097  ]\n",
      "  Ground truth boxes: [[354. 226. 382. 256.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [113.191696 203.04115  188.8889   258.30325 ]\n",
      "  Ground truth boxes: [[130. 226. 158. 256.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [199.84898 167.59976 249.74335 285.80273]\n",
      "  Ground truth boxes: [[197. 192. 252. 275.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [257.86707 195.28351 311.79343 276.26895]\n",
      "  Ground truth boxes: [[260. 192. 315. 275.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [212.06963 153.08492 277.08084 255.33417]\n",
      "  Ground truth boxes: [[208. 149. 271. 253.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [231.19785 143.87416 302.00964 258.47495]\n",
      "  Ground truth boxes: [[241. 149. 304. 253.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [210.86624 211.42268 237.02414 257.8269 ]\n",
      "  Ground truth boxes: [[207. 213. 238. 256.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [272.9113  210.70914 300.31952 258.78235]\n",
      "  Ground truth boxes: [[274. 213. 305. 256.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [148.1093    21.788622 237.41019  104.64457 ]\n",
      "  Ground truth boxes: [[247. 159. 278. 204.]]\n",
      "Image 1:\n",
      "  No high-confidence predicted boxes found\n",
      "Image 1:\n",
      "  No high-confidence predicted boxes found\n",
      "Image 1:\n",
      "  Predicted box with highest score: [119.858154 189.16602  148.13121  264.68436 ]\n",
      "  Ground truth boxes: [[130. 237. 146. 253.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [292.92563 240.64673 336.69562 269.09967]\n",
      "  Ground truth boxes: [[295. 243. 334. 260.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [175.25595 241.55191 217.33134 269.34436]\n",
      "  Ground truth boxes: [[178. 243. 217. 260.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [278.23874 249.52184 314.8558  281.33612]\n",
      "  Ground truth boxes: [[280. 252. 310. 265.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [195.66396 248.19562 232.69478 281.71964]\n",
      "  Ground truth boxes: [[202. 252. 232. 265.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [278.29947 213.61534 307.39743 283.63452]\n",
      "  Ground truth boxes: [[281. 216. 306. 257.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [205.60417 215.83879 235.96066 285.21378]\n",
      "  Ground truth boxes: [[206. 216. 231. 257.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [255.5944  284.7723  292.3093  312.46783]\n",
      "  Ground truth boxes: [[233. 171. 264. 221.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [113.38445 339.37512 148.1937  372.17612]\n",
      "  Ground truth boxes: [[248. 171. 279. 221.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [282.32135 143.40282 307.59756 174.34451]\n",
      "  Ground truth boxes: [[282. 142. 310. 180.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [203.2867  144.33856 228.99506 175.11928]\n",
      "  Ground truth boxes: [[202. 142. 230. 180.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [242.84189 148.92986 263.94168 173.95236]\n",
      "  Ground truth boxes: [[242. 135. 262. 179.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [242.64561 149.836   268.15762 177.42427]\n",
      "  Ground truth boxes: [[250. 135. 270. 179.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [218.18561 249.99654 244.87915 324.15695]\n",
      "  Ground truth boxes: [[220. 262. 241. 311.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [267.65762 278.91956 293.58698 323.44656]\n",
      "  Ground truth boxes: [[271. 262. 292. 311.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [323.92773 253.56721 362.15265 281.95984]\n",
      "  Ground truth boxes: [[326. 257. 376. 278.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [149.50421 254.10603 186.66965 283.1741 ]\n",
      "  Ground truth boxes: [[136. 257. 186. 278.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [266.43637 254.40817 300.35294 283.2548 ]\n",
      "  Ground truth boxes: [[264. 253. 292. 271.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [209.48398 253.04607 245.1121  282.69022]\n",
      "  Ground truth boxes: [[220. 253. 248. 271.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [311.85184 283.87506 346.4229  305.51553]\n",
      "  Ground truth boxes: [[295. 216. 325. 243.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [184.82152 224.67836 213.56586 250.46718]\n",
      "  Ground truth boxes: [[187. 216. 217. 243.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [217.9866  172.55489 263.31628 207.65921]\n",
      "  Ground truth boxes: [[214. 173. 264. 200.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [246.90457 173.67644 294.22336 204.98145]\n",
      "  Ground truth boxes: [[248. 173. 298. 200.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [285.66907 206.57286 327.79813 316.32938]\n",
      "  Ground truth boxes: [[285. 191. 329. 318.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [185.22733 203.51068 225.17998 311.52286]\n",
      "  Ground truth boxes: [[183. 191. 227. 318.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [228.8048  173.9119  304.67422 261.51028]\n",
      "  Ground truth boxes: [[222. 177. 286. 257.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [225.71446 161.15877 286.14285 266.22372]\n",
      "  Ground truth boxes: [[226. 177. 290. 257.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [212.2657  115.02309 238.55424 135.89963]\n",
      "  Ground truth boxes: [[166. 362. 182. 381.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [276.8372   112.794174 300.5303   132.68317 ]\n",
      "  Ground truth boxes: [[330. 362. 346. 381.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [154.7675  159.1108  190.7486  186.38124]\n",
      "  Ground truth boxes: [[148. 422. 167. 451.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [359.72098 181.41847 405.53278 212.1362 ]\n",
      "  Ground truth boxes: [[345. 422. 364. 451.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [287.80795 301.3022  309.25262 329.87463]\n",
      "  Ground truth boxes: [[284. 295. 311. 331.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [272.60483 278.56378 301.20032 304.97507]\n",
      "  Ground truth boxes: [[201. 295. 228. 331.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [248.23285 137.03275 311.84192 200.0565 ]\n",
      "  Ground truth boxes: [[288. 261. 314. 297.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [200.015   136.45982 260.70822 195.14282]\n",
      "  Ground truth boxes: [[198. 261. 224. 297.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [391.48776 284.98068 406.35684 311.51053]\n",
      "  Ground truth boxes: [[391. 291. 403. 311.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [107.13803  284.8373   121.989655 311.21918 ]\n",
      "  Ground truth boxes: [[109. 291. 121. 311.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [179.3859  160.17982 223.99019 193.15196]\n",
      "  Ground truth boxes: [[178. 155. 212. 177.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [285.07443 160.73618 328.25195 187.99442]\n",
      "  Ground truth boxes: [[300. 155. 334. 177.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [232.64296 205.27884 276.26227 233.62349]\n",
      "  Ground truth boxes: [[229. 205. 274. 230.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [235.4066  204.4765  277.25397 234.23216]\n",
      "  Ground truth boxes: [[238. 205. 283. 230.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [ 97.13196 231.66078 189.40433 289.66397]\n",
      "  Ground truth boxes: [[288. 182. 317. 206.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [325.2027  234.6353  421.27277 288.33057]\n",
      "  Ground truth boxes: [[195. 182. 224. 206.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [265.7237  240.9924  317.67773 300.05478]\n",
      "  Ground truth boxes: [[264. 239. 314. 287.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [194.67842 237.9683  246.57977 299.8417 ]\n",
      "  Ground truth boxes: [[198. 239. 248. 287.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [249.5823  219.54413 299.11035 255.7832 ]\n",
      "  Ground truth boxes: [[247. 225. 296. 257.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [213.42236 222.36613 267.76022 254.04004]\n",
      "  Ground truth boxes: [[216. 225. 265. 257.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [214.08003 203.25446 242.70473 253.37152]\n",
      "  Ground truth boxes: [[211. 204. 241. 245.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [268.94592 203.83772 297.93463 251.5591 ]\n",
      "  Ground truth boxes: [[271. 204. 301. 245.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [248.02982 157.15173 271.812   184.46689]\n",
      "  Ground truth boxes: [[242. 155. 273. 186.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [240.14929 154.21742 267.67618 186.46262]\n",
      "  Ground truth boxes: [[239. 155. 270. 186.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [214.4362  228.29265 231.02567 252.91417]\n",
      "  Ground truth boxes: [[215. 232. 230. 250.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [279.66226 228.23996 297.7859  252.32382]\n",
      "  Ground truth boxes: [[282. 232. 297. 250.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [215.82906 277.2574  234.64757 302.2645 ]\n",
      "  Ground truth boxes: [[215. 285. 233. 299.]]\n",
      "Image 1:\n",
      "  Predicted box with highest score: [279.30957 275.6455  294.62244 303.268  ]\n",
      "  Ground truth boxes: [[279. 285. 297. 299.]]\n",
      "Mean Average Precision (mAP) at IoU threshold 0.5: 0.5182\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, device, score_threshold=0.001):\n",
    "    model.eval()\n",
    "    pred_boxes_list = []\n",
    "    gt_boxes_list = []\n",
    "\n",
    "    for images, targets in test_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Move images and targets back to CPU\n",
    "        targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "        outputs = [{k: v.cpu().detach() for k, v in t.items()} for t in outputs]\n",
    "\n",
    "        for idx in range(len(images)):\n",
    "            print(f\"Image {idx + 1}:\")\n",
    "            if 'boxes' in outputs[idx]:\n",
    "                pred_boxes = outputs[idx]['boxes']\n",
    "                pred_scores = outputs[idx]['scores']\n",
    "                pred_labels = outputs[idx]['labels']\n",
    "\n",
    "                # Filter out background predictions\n",
    "                keep = pred_labels == 1  # Assuming label 1 is for the object and 0 is for the background\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "\n",
    "                # Further filter by confidence score\n",
    "                keep = pred_scores >= score_threshold\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "\n",
    "                if len(pred_boxes) > 0:\n",
    "                    # Select the predicted box with the highest score\n",
    "                    best_pred_idx = torch.argmax(pred_scores)\n",
    "                    best_pred_box = pred_boxes[best_pred_idx].numpy()\n",
    "\n",
    "                    pred_boxes_list.append([best_pred_box])\n",
    "                    gt_boxes_list.append(targets[idx]['boxes'].detach().numpy())\n",
    "\n",
    "                    print(f\"  Predicted box with highest score: {best_pred_box}\")\n",
    "                    print(f\"  Ground truth boxes: {targets[idx]['boxes'].detach().numpy()}\")\n",
    "                else:\n",
    "                    print(\"  No high-confidence predicted boxes found\")\n",
    "                    pred_boxes_list.append(np.array([]))\n",
    "                    gt_boxes_list.append(targets[idx]['boxes'].detach().numpy())\n",
    "            else:\n",
    "                print(\"  No predicted boxes found\")\n",
    "                pred_boxes_list.append(np.array([]))\n",
    "                gt_boxes_list.append(targets[idx]['boxes'].detach().numpy())\n",
    "\n",
    "    # Calculate mAP\n",
    "    iou_threshold = 0.5\n",
    "    map_score = mean_average_precision(pred_boxes_list, gt_boxes_list, iou_threshold)\n",
    "    print(f\"Mean Average Precision (mAP) at IoU threshold {iou_threshold}: {map_score:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "evaluate_model(model, test_loader, device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:27:45.613104Z",
     "start_time": "2024-07-28T21:27:43.300414Z"
    }
   },
   "id": "3776930c63df8c8b"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T03:40:16.228079Z",
     "start_time": "2024-07-28T03:40:16.073028Z"
    }
   },
   "id": "c1ef8c533a0b69d"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1:\n",
      "  Predicted boxes: tensor([], size=(0, 4), grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([], grad_fn=<IndexBackward0>)\n",
      "Image 2:\n",
      "  Predicted boxes: tensor([], size=(0, 4), grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([], grad_fn=<IndexBackward0>)\n",
      "Image 3:\n",
      "  Predicted boxes: tensor([[233.1383, 255.1520, 275.8012, 290.4488],\n",
      "        [236.0143, 257.7216, 257.0957, 286.6114]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.1541, 0.0587], grad_fn=<IndexBackward0>)\n",
      "Image 4:\n",
      "  Predicted boxes: tensor([[241.3626, 256.1372, 277.3859, 290.2679],\n",
      "        [240.0285, 256.9294, 270.4097, 277.5441],\n",
      "        [215.3352, 247.3060, 274.2635, 288.7834],\n",
      "        [235.1245, 253.9122, 263.1097, 285.6506],\n",
      "        [204.2471, 252.5560, 248.5094, 281.1637]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.6649, 0.0785, 0.0692, 0.0620, 0.0594], grad_fn=<IndexBackward0>)\n",
      "Image 5:\n",
      "  Predicted boxes: tensor([[247.1892, 125.2482, 312.8375, 168.4076],\n",
      "        [246.1432, 132.2890, 259.8816, 149.7385],\n",
      "        [245.0487, 129.7749, 289.7711, 161.2159],\n",
      "        [244.3487, 130.2030, 267.4280, 151.5580],\n",
      "        [277.9858, 127.8542, 316.2282, 167.9893],\n",
      "        [237.2788, 129.0342, 260.3098, 150.5510]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.3930, 0.1692, 0.0659, 0.0639, 0.0618, 0.0586],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Image 6:\n",
      "  Predicted boxes: tensor([[199.5735, 123.6140, 266.9835, 166.8219],\n",
      "        [226.6102, 127.8837, 269.2535, 161.5693],\n",
      "        [250.1405, 130.5809, 269.3127, 151.1306]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.1481, 0.0696, 0.0610], grad_fn=<IndexBackward0>)\n",
      "Image 7:\n",
      "  Predicted boxes: tensor([[264.6036, 282.9901, 318.8080, 316.9475],\n",
      "        [210.5965, 290.3763, 247.4460, 331.8618],\n",
      "        [238.0799, 278.3976, 314.0753, 322.9583],\n",
      "        [269.7743, 328.0216, 284.2305, 355.2357],\n",
      "        [242.0572, 286.5247, 285.4512, 319.5452],\n",
      "        [181.1918, 270.2381, 254.2770, 333.6036],\n",
      "        [205.1983, 283.2846, 275.1066, 329.9868],\n",
      "        [283.1095, 271.9469, 319.4400, 314.4287],\n",
      "        [169.2669, 198.5957, 209.2463, 242.5283]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.1766, 0.1458, 0.1417, 0.0721, 0.0674, 0.0668, 0.0647, 0.0646, 0.0604],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Image 8:\n",
      "  Predicted boxes: tensor([[193.0622, 276.8640, 236.1567, 315.1916],\n",
      "        [203.6538, 278.6910, 307.4287, 325.7552],\n",
      "        [197.4524, 281.2528, 262.8002, 318.0416],\n",
      "        [266.3052, 290.2928, 319.2246, 332.2800],\n",
      "        [236.4147, 287.1118, 277.6844, 317.4205],\n",
      "        [260.7941, 286.4965, 297.0085, 330.2954],\n",
      "        [249.9955, 282.5402, 284.1290, 327.2828],\n",
      "        [247.9267, 279.3086, 329.6054, 326.4890],\n",
      "        [229.9951, 287.6378, 260.3486, 313.5467],\n",
      "        [246.6380, 291.5854, 273.1825, 315.0688],\n",
      "        [307.9548, 202.8489, 342.8593, 242.0588],\n",
      "        [241.3949, 288.0624, 255.8643, 312.7808]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.5346, 0.2345, 0.2170, 0.1985, 0.1262, 0.1220, 0.1049, 0.0939, 0.0766,\n",
      "        0.0746, 0.0631, 0.0542], grad_fn=<IndexBackward0>)\n",
      "Image 9:\n",
      "  Predicted boxes: tensor([[293.9339, 276.4755, 367.1327, 356.3650]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.4660], grad_fn=<IndexBackward0>)\n",
      "Image 10:\n",
      "  Predicted boxes: tensor([[143.1613, 279.4682, 224.7217, 350.8792],\n",
      "        [145.5029, 300.4335, 211.7082, 340.2719],\n",
      "        [189.5482, 310.6685, 215.9840, 334.2175],\n",
      "        [175.4339, 308.1883, 222.0708, 335.8098],\n",
      "        [118.9201, 258.9615, 213.3718, 358.1134]], grad_fn=<IndexBackward0>)\n",
      "  Predicted scores: tensor([0.5627, 0.1950, 0.1547, 0.0918, 0.0736], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "# Function to print predicted bounding boxes and scores\n",
    "def print_predictions(model, test_loader, device, score_threshold=0):\n",
    "    model.eval()\n",
    "    \n",
    "    num_images = 10  # Number of images to print predictions for\n",
    "    images_processed = 0\n",
    "\n",
    "    for images, targets in test_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Move images and targets back to CPU for debugging and plotting\n",
    "        images = [image.cpu().numpy().transpose((1, 2, 0)) for image in images]\n",
    "        targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "        outputs = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n",
    "\n",
    "        for idx in range(len(images)):\n",
    "            if images_processed >= num_images:\n",
    "                break\n",
    "\n",
    "            print(f\"Image {images_processed + 1}:\")\n",
    "            if 'boxes' in outputs[idx]:\n",
    "                pred_boxes = outputs[idx]['boxes']\n",
    "                pred_scores = outputs[idx]['scores']\n",
    "                pred_labels = outputs[idx]['labels']\n",
    "\n",
    "                # Filter out background predictions\n",
    "                keep = pred_labels == 1  # Assuming label 1 is for the object and 0 is for the background\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "\n",
    "                # Further filter by confidence score\n",
    "                keep = pred_scores >= score_threshold\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "\n",
    "                print(f\"  Predicted boxes: {pred_boxes}\")\n",
    "                print(f\"  Predicted scores: {pred_scores}\")\n",
    "            else:\n",
    "                print(\"  No predicted boxes found\")\n",
    "\n",
    "            images_processed += 1\n",
    "\n",
    "        if images_processed >= num_images:\n",
    "            break\n",
    "\n",
    "# Example usage\n",
    "print_predictions(model, test_loader, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T22:00:48.782699Z",
     "start_time": "2024-07-27T22:00:48.206829Z"
    }
   },
   "id": "22acf5e5d8aedfe5"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two boxes.\"\"\"\n",
    "    x1_max = max(box1[0], box2[0])\n",
    "    y1_max = max(box1[1], box2[1])\n",
    "    x2_min = min(box1[2], box2[2])\n",
    "    y2_min = min(box1[3], box2[3])\n",
    "\n",
    "    intersection = max(0, x2_min - x1_max) * max(0, y2_min - y1_max)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = box1_area + box2_area - intersection\n",
    "\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def plot_image_with_boxes(image, gt_boxes, pred_box, ax):\n",
    "    ax.imshow(image)\n",
    "    # Plot ground truth boxes in blue\n",
    "    for box in gt_boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor='blue', linewidth=2, label='Ground Truth')\n",
    "        ax.add_patch(rect)\n",
    "    # Plot predicted box in red\n",
    "    if pred_box is not None:\n",
    "        xmin, ymin, xmax, ymax = pred_box\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor='red', linewidth=2, label='Prediction')\n",
    "        ax.add_patch(rect)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))\n",
    "    ax.legend(unique_labels.values(), unique_labels.keys())\n",
    "\n",
    "def visualize_predictions(model, test_loader, device, score_threshold=0.001):\n",
    "    model.eval()\n",
    "\n",
    "    for images, targets in test_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Move images and targets back to CPU for debugging and plotting\n",
    "        images = [image.cpu().detach().numpy().transpose((1, 2, 0)) for image in images]\n",
    "        targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "        outputs = [{k: v.cpu().detach() for k, v in t.items()} for t in outputs]\n",
    "\n",
    "        for idx in range(len(images)):\n",
    "            print(f\"Image {idx + 1}:\")\n",
    "            if 'boxes' in outputs[idx]:\n",
    "                pred_boxes = outputs[idx]['boxes']\n",
    "                pred_scores = outputs[idx]['scores']\n",
    "                pred_labels = outputs[idx]['labels']\n",
    "\n",
    "                # Filter out background predictions\n",
    "                keep = pred_labels == 1  # Assuming label 1 is for the object and 0 is for the background\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "\n",
    "                # Further filter by confidence score\n",
    "                keep = pred_scores >= score_threshold\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "\n",
    "                if len(pred_boxes) > 0:\n",
    "                    # Compute IoU and find the box with the highest IoU with any ground truth box\n",
    "                    gt_boxes = targets[idx]['boxes'].detach().numpy()\n",
    "                    best_iou = 0\n",
    "                    best_box = None\n",
    "                    for pred_box in pred_boxes:\n",
    "                        for gt_box in gt_boxes:\n",
    "                            iou = compute_iou(pred_box.numpy(), gt_box)\n",
    "                            if iou > best_iou:\n",
    "                                best_iou = iou\n",
    "                                best_box = pred_box\n",
    "\n",
    "                    print(f\"  Predicted box with highest IoU: {best_box}\")\n",
    "                    print(f\"  Predicted scores: {pred_scores}\")\n",
    "                    \n",
    "                    # Plot the images with ground truth and the best predicted box\n",
    "                    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "                    plot_image_with_boxes(images[idx], gt_boxes, best_box.detach().numpy() if best_box is not None else None, ax)\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"  No high-confidence predicted boxes found\")\n",
    "            else:\n",
    "                print(\"  No predicted boxes found\")\n",
    "\n",
    "# Example usage\n",
    "visualize_predictions(model, test_loader, device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ef8413db4129fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two boxes.\"\"\"\n",
    "    x1_max = max(box1[0], box2[0])\n",
    "    y1_max = max(box1[1], box2[1])\n",
    "    x2_min = min(box1[2], box2[2])\n",
    "    y2_min = min(box1[3], box2[3])\n",
    "\n",
    "    intersection = max(0, x2_min - x1_max) * max(0, y2_min - y1_max)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = box1_area + box2_area - intersection\n",
    "\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def precision_recall_f1(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for pred_box in pred_boxes:\n",
    "        iou_max = 0\n",
    "        for gt_box in gt_boxes:\n",
    "            iou = compute_iou(pred_box, gt_box)\n",
    "            if iou > iou_max:\n",
    "                iou_max = iou\n",
    "        if iou_max >= iou_threshold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    fn = len(gt_boxes) - tp\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def average_precision(precisions, recalls):\n",
    "    \"\"\"Calculate the Average Precision (AP) from precision and recall values.\"\"\"\n",
    "    precisions = np.concatenate([[0], precisions, [0]])\n",
    "    recalls = np.concatenate([[0], recalls, [1]])\n",
    "\n",
    "    for i in range(len(precisions) - 1, 0, -1):\n",
    "        precisions[i - 1] = max(precisions[i - 1], precisions[i])\n",
    "\n",
    "    indices = np.where(recalls[1:] != recalls[:-1])[0]\n",
    "    ap = np.sum((recalls[indices + 1] - recalls[indices]) * precisions[indices + 1])\n",
    "    return ap\n",
    "\n",
    "def mean_average_precision(pred_boxes_list, gt_boxes_list, iou_threshold=0.5):\n",
    "    aps = []\n",
    "\n",
    "    for i in range(len(pred_boxes_list)):\n",
    "        pred_boxes = pred_boxes_list[i]\n",
    "        gt_boxes = gt_boxes_list[i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_f1(pred_boxes, gt_boxes, iou_threshold)\n",
    "\n",
    "        precisions = [precision]\n",
    "        recalls = [recall]\n",
    "\n",
    "        ap = average_precision(np.array(precisions), np.array(recalls))\n",
    "        aps.append(ap)\n",
    "\n",
    "    mAP = np.mean(aps)\n",
    "    return mAP\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T21:24:46.920556Z",
     "start_time": "2024-07-28T21:24:46.883314Z"
    }
   },
   "id": "439028db2cbdca4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "True Positive (TP):\n",
    "\n",
    "A predicted bounding box is considered a true positive if it matches a ground truth bounding box with an IoU greater than or equal to the specified threshold (e.g., 0.5).\n",
    "Each ground truth bounding box should be matched to only one predicted bounding box.\n",
    "False Positive (FP):\n",
    "\n",
    "A predicted bounding box is considered a false positive if it does not match any ground truth bounding box with an IoU greater than or equal to the specified threshold.\n",
    "This can occur if the predicted box overlaps with no ground truth box or if the IoU is below the threshold.\n",
    "False Negative (FN):\n",
    "\n",
    "A ground truth bounding box is considered a false negative if it does not have any matching predicted bounding box with an IoU greater than or equal to the specified threshold.\n",
    "This indicates a missed detection."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "951468633a8c5282"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
